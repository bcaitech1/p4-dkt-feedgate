{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"oof stacking, pseudo labeling.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Nv5EvIVPnz0y"},"source":["# OOF stacking\n","> 7ê°• oof stackingì„ ë² ì´ìŠ¤ë¼ì¸ì— êµ¬í˜„í•´ë³´ëŠ” í€´ì¦ˆì˜ ì •ë‹µ ì½”ë“œì…ë‹ˆë‹¤! ì•„ë˜ ë² ì´ìŠ¤ë¼ì¸ì€ ê·¸ëŒ€ë¡œ ì‹¤í–‰ì‹œì¼œì£¼ì‹œê³  `oof stacking` íŒŒíŠ¸ì—ì„œ ì‹œì‘í•´ì£¼ì‹œë©´ ë©ë‹ˆë‹¤! ë² ì´ìŠ¤ë¼ì¸ì˜ `run`í•¨ìˆ˜ëŠ” ì‚¬ìš©ë˜ì§€ ì•ŠëŠ”ë‹¤ëŠ” ì ì— ì£¼ì˜í•´ì£¼ì„¸ìš”!"]},{"cell_type":"markdown","metadata":{"id":"7J9jlW4kWXHz"},"source":["## ë² ì´ìŠ¤ë¼ì¸\n","> ì²˜ìŒì— ì£¼ì–´ì§€ëŠ” ë…¸íŠ¸ë¶ ë² ì´ìŠ¤ë¼ì¸ ì½”ë“œì…ë‹ˆë‹¤!"]},{"cell_type":"code","metadata":{"id":"O0K8EgjkWXH0","outputId":"cfd9de16-46cb-42f9-a7d0-f0e7196467fc"},"source":["!pip install easydict"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: easydict in /opt/conda/lib/python3.7/site-packages (1.9)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wtJhitPznz06","tags":[]},"source":["import pandas as pd\n","import os\n","import torch\n","import easydict\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder\n","import time\n","import datetime\n","from datetime import datetime\n","import random\n","import wandb"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6w3E-ACunz07"},"source":["### 1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ ì»´í¬ë„ŒíŠ¸"]},{"cell_type":"code","metadata":{"id":"od9O-ttAnz08","tags":[]},"source":["import os\n","from datetime import datetime\n","import time\n","import tqdm\n","import pandas as pd\n","import random\n","from sklearn.preprocessing import LabelEncoder\n","import numpy as np\n","import torch\n","\n","class Preprocess:\n","    def __init__(self,args):\n","        self.args = args\n","        self.train_data = None\n","        self.test_data = None\n","        \n","\n","    def get_train_data(self):\n","        return self.train_data\n","\n","    def get_test_data(self):\n","        return self.test_data\n","\n","    def split_data(self, data, ratio=0.7, shuffle=True, seed=0):\n","        \"\"\"\n","        split data into two parts with a given ratio.\n","        \"\"\"\n","        if shuffle:\n","            random.seed(seed) # fix to default seed 0\n","            random.shuffle(data)\n","\n","        size = int(len(data) * ratio)\n","        data_1 = data[:size]\n","        data_2 = data[size:]\n","\n","        return data_1, data_2\n","\n","    def __save_labels(self, encoder, name):\n","        le_path = os.path.join(self.args.asset_dir, name + '_classes.npy')\n","        np.save(le_path, encoder.classes_)\n","\n","    def __preprocessing(self, df, is_train = True):\n","        cate_cols = ['assessmentItemID', 'testId', 'KnowledgeTag']\n","\n","        if not os.path.exists(self.args.asset_dir):\n","            os.makedirs(self.args.asset_dir)\n","            \n","        for col in cate_cols:\n","            \n","            \n","            le = LabelEncoder()\n","            if is_train:\n","                #For UNKNOWN class\n","                a = df[col].unique().tolist() + ['unknown']\n","                le.fit(a)\n","                self.__save_labels(le, col)\n","            else:\n","                label_path = os.path.join(self.args.asset_dir,col+'_classes.npy')\n","                le.classes_ = np.load(label_path)\n","                \n","                df[col] = df[col].apply(lambda x: x if x in le.classes_ else 'unknown')\n","\n","            #ëª¨ë“  ì»¬ëŸ¼ì´ ë²”ì£¼í˜•ì´ë¼ê³  ê°€ì •\n","            df[col]= df[col].astype(str)\n","            test = le.transform(df[col])\n","            df[col] = test\n","            \n","\n","        def convert_time(s):\n","            timestamp = time.mktime(datetime.strptime(s, '%Y-%m-%d %H:%M:%S').timetuple())\n","            return int(timestamp)\n","\n","        df['Timestamp'] = df['Timestamp'].apply(convert_time)\n","        \n","        return df\n","\n","    def __feature_engineering(self, df):\n","        #TODO\n","        return df\n","\n","    def load_data_from_file(self, file_name, is_train=True):\n","        csv_file_path = os.path.join(self.args.data_dir, file_name)\n","        df = pd.read_csv(csv_file_path)#, nrows=100000)\n","        df = self.__feature_engineering(df)\n","        df = self.__preprocessing(df, is_train)\n","\n","        # ì¶”í›„ featureë¥¼ embeddingí•  ì‹œì— embedding_layerì˜ input í¬ê¸°ë¥¼ ê²°ì •í• ë•Œ ì‚¬ìš©\n","\n","                \n","        self.args.n_questions = len(np.load(os.path.join(self.args.asset_dir,'assessmentItemID_classes.npy')))\n","        self.args.n_test = len(np.load(os.path.join(self.args.asset_dir,'testId_classes.npy')))\n","        self.args.n_tag = len(np.load(os.path.join(self.args.asset_dir,'KnowledgeTag_classes.npy')))\n","        \n","\n","\n","        df = df.sort_values(by=['userID','Timestamp'], axis=0)\n","        columns = ['userID', 'assessmentItemID', 'testId', 'answerCode', 'KnowledgeTag']\n","        group = df[columns].groupby('userID').apply(\n","                lambda r: (\n","                    r['testId'].values, \n","                    r['assessmentItemID'].values,\n","                    r['KnowledgeTag'].values,\n","                    r['answerCode'].values\n","                )\n","            )\n","\n","        return group.values\n","\n","    def load_train_data(self, file_name):\n","        self.train_data = self.load_data_from_file(file_name)\n","\n","    def load_test_data(self, file_name):\n","        self.test_data = self.load_data_from_file(file_name, is_train=False)\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E-MQhPevnz08"},"source":["### 2. ë°ì´í„° ì…‹ / ë°ì´í„° ë¡œë”"]},{"cell_type":"code","metadata":{"id":"h29rn8YNnz09","tags":[]},"source":["class DKTDataset(torch.utils.data.Dataset):\n","    def __init__(self, data, args):\n","        self.data = data\n","        self.args = args\n","\n","    def __getitem__(self, index):\n","        row = self.data[index]\n","\n","        # ê° dataì˜ sequence length\n","        seq_len = len(row[0])\n","\n","        test, question, tag, correct = row[0], row[1], row[2], row[3]\n","        \n","\n","        cate_cols = [test, question, tag, correct]\n","\n","        # max seq lenì„ ê³ ë ¤í•˜ì—¬ì„œ ì´ë³´ë‹¤ ê¸¸ë©´ ìë¥´ê³  ì•„ë‹ ê²½ìš° ê·¸ëŒ€ë¡œ ëƒ…ë‘”ë‹¤\n","        if seq_len > self.args.max_seq_len:\n","            for i, col in enumerate(cate_cols):\n","                cate_cols[i] = col[-self.args.max_seq_len:]\n","            mask = np.ones(self.args.max_seq_len, dtype=np.int16)\n","        else:\n","            mask = np.zeros(self.args.max_seq_len, dtype=np.int16)\n","            mask[-seq_len:] = 1\n","\n","        # maskë„ columns ëª©ë¡ì— í¬í•¨ì‹œí‚´\n","        cate_cols.append(mask)\n","\n","        # np.array -> torch.tensor í˜•ë³€í™˜\n","        for i, col in enumerate(cate_cols):\n","            cate_cols[i] = torch.tensor(col)\n","\n","        return cate_cols\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","\n","\n","\n","def collate(batch):\n","    col_n = len(batch[0])\n","    col_list = [[] for _ in range(col_n)]\n","    max_seq_len = len(batch[0][-1])\n","\n","        \n","    # batchì˜ ê°’ë“¤ì„ ê° columnë¼ë¦¬ ê·¸ë£¹í™”\n","    for row in batch:\n","        for i, col in enumerate(row):\n","            pre_padded = torch.zeros(max_seq_len)\n","            pre_padded[-len(col):] = col\n","            col_list[i].append(pre_padded)\n","\n","\n","    for i, _ in enumerate(col_list):\n","        col_list[i] =torch.stack(col_list[i])\n","    \n","    return tuple(col_list)\n","\n","\n","def get_loaders(args, train, valid):\n","\n","    pin_memory = False\n","    train_loader, valid_loader = None, None\n","    \n","    if train is not None:\n","        trainset = DKTDataset(train, args)\n","        train_loader = torch.utils.data.DataLoader(trainset, num_workers=args.num_workers, shuffle=True,\n","                            batch_size=args.batch_size, pin_memory=pin_memory, collate_fn=collate)\n","    if valid is not None:\n","        valset = DKTDataset(valid, args)\n","        valid_loader = torch.utils.data.DataLoader(valset, num_workers=args.num_workers, shuffle=False,\n","                            batch_size=args.batch_size, pin_memory=pin_memory, collate_fn=collate)\n","\n","    return train_loader, valid_loader"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QyiplxY6nz0-"},"source":["### 3. LSTM ê¸°ë°˜ì˜ ëª¨ë¸"]},{"cell_type":"code","metadata":{"id":"aO72oKAgnz0-","tags":[]},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F \n","import numpy as np\n","import copy\n","import math\n","\n","try:\n","    from transformers.modeling_bert import BertConfig, BertEncoder, BertModel    \n","except:\n","    from transformers.models.bert.modeling_bert import BertConfig, BertEncoder, BertModel    \n","\n","\n","\n","\n","class LSTM(nn.Module):\n","\n","    def __init__(self, args):\n","        super(LSTM, self).__init__()\n","        self.args = args\n","        self.device = args.device\n","\n","        self.hidden_dim = self.args.hidden_dim\n","        self.n_layers = self.args.n_layers\n","\n","        # Embedding \n","        # interactionì€ í˜„ì¬ correctë¡œ êµ¬ì„±ë˜ì–´ìˆë‹¤. correct(1, 2) + padding(0)\n","        self.embedding_interaction = nn.Embedding(3, self.hidden_dim//3)\n","        self.embedding_test = nn.Embedding(self.args.n_test + 1, self.hidden_dim//3)\n","        self.embedding_question = nn.Embedding(self.args.n_questions + 1, self.hidden_dim//3)\n","        self.embedding_tag = nn.Embedding(self.args.n_tag + 1, self.hidden_dim//3)\n","\n","        # embedding combination projection\n","        self.comb_proj = nn.Linear((self.hidden_dim//3)*4, self.hidden_dim)\n","\n","        self.lstm = nn.LSTM(self.hidden_dim,\n","                            self.hidden_dim,\n","                            self.n_layers,\n","                            batch_first=True)\n","        \n","        # Fully connected layer\n","        self.fc = nn.Linear(self.hidden_dim, 1)\n","\n","        self.activation = nn.Sigmoid()\n","\n","    def init_hidden(self, batch_size):\n","        h = torch.zeros(\n","            self.n_layers,\n","            batch_size,\n","            self.hidden_dim)\n","        h = h.to(self.device)\n","\n","        c = torch.zeros(\n","            self.n_layers,\n","            batch_size,\n","            self.hidden_dim)\n","        c = c.to(self.device)\n","\n","        return (h, c)\n","\n","    def forward(self, input):\n","\n","        test, question, tag, _, mask, interaction, _ = input\n","\n","        batch_size = interaction.size(0)\n","\n","        # Embedding\n","\n","        embed_interaction = self.embedding_interaction(interaction)\n","        embed_test = self.embedding_test(test)\n","        embed_question = self.embedding_question(question)\n","        embed_tag = self.embedding_tag(tag)\n","        \n","\n","        embed = torch.cat([embed_interaction,\n","                           embed_test,\n","                           embed_question,\n","                           embed_tag,], 2)\n","\n","        X = self.comb_proj(embed)\n","\n","        hidden = self.init_hidden(batch_size)\n","        out, hidden = self.lstm(X, hidden)\n","        out = out.contiguous().view(batch_size, -1, self.hidden_dim)\n","\n","        out = self.fc(out)\n","        preds = self.activation(out).view(batch_size, -1)\n","\n","        return preds\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NEaAa6Prnz0_"},"source":["### 4. ëª¨ë¸ í›ˆë ¨ì„ ìœ„í•œ í•¨ìˆ˜ë“¤"]},{"cell_type":"code","metadata":{"id":"r_wU37QGnz0_","tags":[]},"source":["import os, sys\n","\n","import numpy as np\n","\n","import tarfile\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","from torch.optim import Adam, AdamW\n","\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","\n","from transformers import get_linear_schedule_with_warmup\n","from transformers import get_cosine_schedule_with_warmup\n","\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import accuracy_score\n","import scipy.stats\n","\n","\n","# í›ˆë ¨ì„ í•˜ê¸° ìœ„í•œ ì„¸íŒ…\n","def get_optimizer(model, args):\n","    if args.optimizer == 'adam':\n","        optimizer = Adam(model.parameters(), lr=args.lr, weight_decay=0.01)\n","    if args.optimizer == 'adamW':\n","        optimizer = AdamW(model.parameters(), lr=args.lr, weight_decay=0.01)\n","    \n","    # ëª¨ë“  parameterë“¤ì˜ gradê°’ì„ 0ìœ¼ë¡œ ì´ˆê¸°í™”\n","    optimizer.zero_grad()\n","    \n","    return optimizer\n","\n","def get_scheduler(optimizer, args):\n","    if args.scheduler == 'plateau':\n","        scheduler = ReduceLROnPlateau(optimizer, patience=10, factor=0.5, mode='max', verbose=True)\n","    elif args.scheduler == 'linear_warmup':\n","        scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                                    num_warmup_steps=args.warmup_steps,\n","                                                    num_training_steps=args.total_steps)\n","    return scheduler\n","\n","def get_criterion(pred, target):\n","    loss = nn.BCELoss(reduction=\"none\")\n","    return loss(pred, target)\n","\n","def get_metric(targets, preds):\n","    auc = roc_auc_score(targets, preds)\n","    acc = accuracy_score(targets, np.where(preds >= 0.5, 1, 0))\n","\n","    return auc, acc\n","\n","def get_model(args):\n","    \"\"\"\n","    Load model and move tensors to a given devices.\n","    \"\"\"\n","    if args.model == 'lstm': model = LSTM(args)\n","    \n","\n","    model.to(args.device)\n","\n","    return model\n","\n","\n","# ë°°ì¹˜ ì „ì²˜ë¦¬\n","def process_batch(batch, args):\n","\n","    test, question, tag, correct, mask = batch\n","    \n","    \n","    # change to float\n","    mask = mask.type(torch.FloatTensor)\n","    correct = correct.type(torch.FloatTensor)\n","\n","    #  interactionì„ ì„ì‹œì ìœ¼ë¡œ correctë¥¼ í•œì¹¸ ìš°ì¸¡ìœ¼ë¡œ ì´ë™í•œ ê²ƒìœ¼ë¡œ ì‚¬ìš©\n","    #    saintì˜ ê²½ìš° decoderì— ë“¤ì–´ê°€ëŠ” inputì´ë‹¤\n","    interaction = correct + 1 # íŒ¨ë”©ì„ ìœ„í•´ correctê°’ì— 1ì„ ë”í•´ì¤€ë‹¤.\n","    interaction = interaction.roll(shifts=1, dims=1)\n","    interaction[:, 0] = 0 # set padding index to the first sequence\n","    interaction = (interaction * mask).to(torch.int64)\n","    # print(interaction)\n","    # exit()\n","    #  test_id, question_id, tag\n","    test = ((test + 1) * mask).to(torch.int64)\n","    question = ((question + 1) * mask).to(torch.int64)\n","    tag = ((tag + 1) * mask).to(torch.int64)\n","\n","    # gather index\n","    # ë§ˆì§€ë§‰ sequenceë§Œ ì‚¬ìš©í•˜ê¸° ìœ„í•œ index\n","    gather_index = torch.tensor(np.count_nonzero(mask, axis=1))\n","    gather_index = gather_index.view(-1, 1) - 1\n","\n","\n","    # device memoryë¡œ ì´ë™\n","\n","    test = test.to(args.device)\n","    question = question.to(args.device)\n","\n","\n","    tag = tag.to(args.device)\n","    correct = correct.to(args.device)\n","    mask = mask.to(args.device)\n","\n","    interaction = interaction.to(args.device)\n","    gather_index = gather_index.to(args.device)\n","\n","    return (test, question,\n","            tag, correct, mask,\n","            interaction, gather_index)\n","\n","\n","# lossê³„ì‚°í•˜ê³  parameter update!\n","def compute_loss(preds, targets):\n","    \"\"\"\n","    Args :\n","        preds   : (batch_size, max_seq_len)\n","        targets : (batch_size, max_seq_len)\n","\n","    \"\"\"\n","    loss = get_criterion(preds, targets)\n","    #ë§ˆì§€ë§‰ ì‹œí€€ë“œì— ëŒ€í•œ ê°’ë§Œ loss ê³„ì‚°\n","    loss = loss[:,-1]\n","    loss = torch.mean(loss)\n","    return loss\n","\n","def update_params(loss, model, optimizer, args):\n","    loss.backward()\n","    torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip_grad)\n","    optimizer.step()\n","    optimizer.zero_grad()\n","\n","\n","\n","def save_checkpoint(state, model_dir, model_filename):\n","    print('saving model ...')\n","    if not os.path.exists(model_dir):\n","        os.makedirs(model_dir)    \n","    torch.save(state, os.path.join(model_dir, model_filename))\n","\n","\n","\n","def load_model(args):\n","    \n","    \n","    model_path = os.path.join(args.model_dir, args.model_name)\n","    print(\"Loading Model from:\", model_path)\n","    load_state = torch.load(model_path)\n","    model = get_model(args)\n","\n","    # 1. load model state\n","    model.load_state_dict(load_state['state_dict'], strict=True)\n","   \n","    \n","    print(\"Loading Model from:\", model_path, \"...Finished.\")\n","    return model\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YO_xFaJYnz1B"},"source":["### 5. ì „ì²´ í”„ë¡œì„¸ìŠ¤ë¥¼ ë‹´ë‹¹í•˜ëŠ” í•¨ìˆ˜ë“¤"]},{"cell_type":"code","metadata":{"id":"BMiIOHgJnz1D","tags":[]},"source":["def train(train_loader, model, optimizer, args):\n","    model.train()\n","\n","    total_preds = []\n","    total_targets = []\n","    losses = []\n","    for step, batch in enumerate(train_loader):\n","        input = process_batch(batch, args)\n","        preds = model(input)\n","        targets = input[3] # correct\n","\n","\n","        loss = compute_loss(preds, targets)\n","        update_params(loss, model, optimizer, args)\n","\n","        if step % args.log_steps == 0:\n","            print(f\"Training steps: {step} Loss: {str(loss.item())}\")\n","        \n","        # predictions\n","        preds = preds[:,-1]\n","        targets = targets[:,-1]\n","\n","        if args.device == 'cuda':\n","            preds = preds.to('cpu').detach().numpy()\n","            targets = targets.to('cpu').detach().numpy()\n","        else: # cpu\n","            preds = preds.detach().numpy()\n","            targets = targets.detach().numpy()\n","        \n","        total_preds.append(preds)\n","        total_targets.append(targets)\n","        losses.append(loss)\n","      \n","\n","    total_preds = np.concatenate(total_preds)\n","    total_targets = np.concatenate(total_targets)\n","\n","    # Train AUC / ACC\n","    auc, acc = get_metric(total_targets, total_preds)\n","    loss_avg = sum(losses)/len(losses)\n","    print(f'TRAIN AUC : {auc} ACC : {acc}')\n","    return auc, acc, loss_avg\n","    \n","\n","def validate(valid_loader, model, args):\n","    model.eval()\n","\n","    total_preds = []\n","    total_targets = []\n","    for step, batch in enumerate(valid_loader):\n","        input = process_batch(batch, args)\n","\n","        preds = model(input)\n","        targets = input[3] # correct\n","\n","\n","        # predictions\n","        preds = preds[:,-1]\n","        targets = targets[:,-1]\n","    \n","        if args.device == 'cuda':\n","            preds = preds.to('cpu').detach().numpy()\n","            targets = targets.to('cpu').detach().numpy()\n","        else: # cpu\n","            preds = preds.detach().numpy()\n","            targets = targets.detach().numpy()\n","\n","        total_preds.append(preds)\n","        total_targets.append(targets)\n","\n","    total_preds = np.concatenate(total_preds)\n","    total_targets = np.concatenate(total_targets)\n","\n","    # Train AUC / ACC\n","    auc, acc = get_metric(total_targets, total_preds)\n","    \n","    print(f'VALID AUC : {auc} ACC : {acc}\\n')\n","\n","    return auc, acc, total_preds, total_targets\n","\n","\n","\n","def inference(args, test_data):\n","    \n","    model = load_model(args)\n","    model.eval()\n","    _, test_loader = get_loaders(args, None, test_data)\n","    \n","    \n","    total_preds = []\n","    \n","    for step, batch in enumerate(test_loader):\n","        input = process_batch(batch, args)\n","\n","        preds = model(input)\n","        \n","\n","        # predictions\n","        preds = preds[:,-1]\n","        \n","\n","        if args.device == 'cuda':\n","            preds = preds.to('cpu').detach().numpy()\n","        else: # cpu\n","            preds = preds.detach().numpy()\n","            \n","        total_preds += list(preds)\n","\n","    write_path = os.path.join(args.output_dir, \"output.csv\")\n","    if not os.path.exists(args.output_dir):\n","        os.makedirs(args.output_dir)    \n","    with open(write_path, 'w', encoding='utf8') as w:\n","        print(\"writing prediction : {}\".format(write_path))\n","        w.write(\"id,prediction\\n\")\n","        for id, p in enumerate(total_preds):\n","            w.write('{},{}\\n'.format(id,p))\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qZmwQenqnz1E","tags":[]},"source":["data_dir = '/opt/ml/input/data/train_dataset'\n","file_name = 'train_data.csv'\n","test_file_name = 'test_data.csv'\n","\n","config = {}\n","\n","# ì„¤ì •\n","config['seed'] = 42\n","config['device'] = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","config['data_dir'] = data_dir\n","config['asset_dir'] = 'asset'\n","config['model_dir'] = 'models'\n","config['model_name'] = 'model.pt'\n","config['output_dir'] = 'output'\n","\n","# ë°ì´í„°\n","config['max_seq_len'] = 20\n","config['num_workers'] = 1\n","\n","\n","# ëª¨ë¸\n","config['hidden_dim'] = 64\n","config['n_layers'] = 2\n","config['dropout'] = 0.2\n","\n","# í›ˆë ¨\n","config['n_epochs'] = 20\n","config['batch_size'] = 64\n","config['lr'] = 0.0001\n","config['clip_grad'] = 10\n","config['log_steps'] = 50\n","config['patience'] = 5\n","\n","\n","\n","### ì¤‘ìš” ###\n","config['model'] = 'lstm'\n","config['optimizer'] = 'adam'\n","config['scheduler'] = 'plateau'\n","\n","\n","args = easydict.EasyDict(config)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gPEE00qUnz1E"},"source":["## `OOF Stacking`\n","\n","> ì—¬ëŸ¬ë²ˆì˜ ì‹¤í—˜ì„ ê±°ì³ ê°€ì¥ ì¢‹ì€ ì‹¤í—˜ ì„¸íŒ…ì„ ì°¾ì€ í›„ì— ì´ ì„¸íŒ…ê°’ì¸ argsë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ëª¨ë¸ í›ˆë ¨ë¶€í„° oof ìƒì„±, meta ëª¨ë¸ í›ˆë ¨ê¹Œì§€ í•œë²ˆì— í•´ê²°í•˜ëŠ” ëª©ì ì˜ `Stacking` í´ë˜ìŠ¤ì™€ `Trainer` í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ oof stackingì„ ì§„í–‰í•  ê²ƒì´ë‹¤!\n"]},{"cell_type":"markdown","metadata":{"id":"mNkG02NbWXH9"},"source":["### ì½”ë“œ\n","\n","- Trainer\n","- Stacking"]},{"cell_type":"markdown","metadata":{"id":"HB6y8dZkWXH9"},"source":["#### ğŸ’¯ Trainer\n","- ëª¨ë¸ í›ˆë ¨ ë° í›ˆë ¨ëœ ëª¨ë¸ return (ë² ì´ìŠ¤ë¼ì¸ `run`í•¨ìˆ˜ ê¸°ëŠ¥)\n","- ë°ì´í„° ì˜ˆì¸¡ê°’ì¸ predict ê°€ì ¸ì˜¤ê¸°\n","- ë°ì´í„° ë¼ë²¨ì¸ yê°’ ê°€ì ¸ì˜¤ê¸°"]},{"cell_type":"code","metadata":{"tags":[],"id":"HwxR0I3uWXH9"},"source":["from tqdm import tqdm\n","\n","class Trainer:\n","    def __init__(self):\n","        pass\n","\n","    def train(self, args, train_data, valid_data):\n","        \"\"\"í›ˆë ¨ì„ ë§ˆì¹œ ëª¨ë¸ì„ ë°˜í™˜í•œë‹¤\"\"\"\n","\n","        # args update\n","        self.args = args\n","\n","        train_loader, valid_loader = get_loaders(args, train_data, valid_data)\n","        \n","        # only when using warmup scheduler\n","        args.total_steps = int(len(train_loader.dataset) / args.batch_size) * (args.n_epochs)\n","        args.warmup_steps = args.total_steps // 10\n","            \n","        model = get_model(args)\n","        optimizer = get_optimizer(model, args)\n","        scheduler = get_scheduler(optimizer, args)\n","\n","        best_auc = -1\n","        best_model = -1\n","        early_stopping_counter = 0\n","        for epoch in tqdm(range(args.n_epochs)):\n","\n","            ### TRAIN\n","            train_auc, train_acc, loss_avg = train(train_loader, model, optimizer, args)\n","            \n","            ### VALID\n","            auc, acc, preds, targets = validate(valid_loader, model, args)\n","\n","            ### model save or early stopping\n","            if auc > best_auc:\n","                best_auc = auc\n","                best_model = copy.deepcopy(model)\n","                early_stopping_counter = 0\n","            else:\n","                early_stopping_counter += 1\n","                if early_stopping_counter >= args.patience:\n","                    print(f'EarlyStopping counter: {early_stopping_counter} out of {args.patience}')\n","                    break\n","\n","            # scheduler\n","            if args.scheduler == 'plateau':\n","                scheduler.step(best_auc)\n","            else:\n","                scheduler.step()\n","\n","        return best_model\n","\n","    def evaluate(self, args, model, valid_data):\n","        \"\"\"í›ˆë ¨ëœ ëª¨ë¸ê³¼ validation ë°ì´í„°ì…‹ì„ ì œê³µí•˜ë©´ predict ë°˜í™˜\"\"\"\n","        pin_memory = False\n","\n","        valset = DKTDataset(valid_data, args)\n","        valid_loader = torch.utils.data.DataLoader(valset, shuffle=False,\n","                                                   batch_size=args.batch_size,\n","                                                   pin_memory=pin_memory,\n","                                                   collate_fn=collate)\n","\n","        auc, acc, preds, _ = validate(valid_loader, model, args)\n","        print(f\"AUC : {auc}, ACC : {acc}\")\n","\n","        return preds\n","\n","    def test(self, args, model, test_data):\n","        model.eval()\n","        _, test_loader = get_loaders(args, None, test_data)\n","\n","        total_preds = []\n","        for step, batch in enumerate(test_loader):\n","            input = process_batch(batch, args)\n","\n","            preds = model(input)\n","\n","            # predictions\n","            preds = preds[:,-1]\n","\n","            if args.device == 'cuda':\n","                preds = preds.to('cpu').detach().numpy()\n","            else: # cpu\n","                preds = preds.detach().numpy()\n","                \n","            total_preds.append(preds)\n","\n","        total_preds = np.concatenate(total_preds)\n","            \n","        return total_preds\n","\n","    def get_target(self, datas):\n","        targets = []\n","        for data in datas:\n","            targets.append(data[-1][-1])\n","\n","        return np.array(targets)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cSU1Xrj7WXH9"},"source":["#### ğŸ’¯ Stacking\n","> oof stackingì„ í¸ë¦¬í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ customí•˜ê²Œ êµ¬ì¶•ëœ í´ë˜ìŠ¤ë‹¤.\n","- KFold ëª¨ë¸ í›ˆë ¨\n","- train oof ê°€ì ¸ì˜¤ê¸°\n","- train oof stacking\n","- meta ëª¨ë¸ í›ˆë ¨\n","- test avg ê°€ì ¸ì˜¤ê¸°\n","- test avg stacking\n","- testì…‹ ì˜ˆì¸¡\n","\n",">í˜„ì¬ DKTëŒ€íšŒì— ë§ê²Œ ì„¤ê³„ë˜ì–´ìˆìœ¼ë©° ìœ ì‚¬í•œ í˜•íƒœì˜ ë°ì´í„°ì˜ ê²½ìš° `Trainer`ì˜ ì½”ë“œë§Œ ë°”ê¾¸ë©´ ê·¸ëŒ€ë¡œ ì¬ì‚¬ìš©ì´ ê°€ëŠ¥í•˜ì§€ë§Œ ë°ì´í„°ì˜ í˜•íƒœê°€ ë‹¤ë¥¼ ê²½ìš°(pandas DataFrame, ì´ë¯¸ì§€ ë“±) `Stacking` ì½”ë“œë„ í•´ë‹¹ ë°ì´í„°ì— ë§ê²Œ ì¬êµ¬ì¶•í•˜ê±°ë‚˜, í˜¹ì€ ë°ì´í„° ì…ë ¥ì„ `Stacking` ì½”ë“œ ì…ë ¥ í˜•ì‹ì— ë§ì¶° ë„£ì–´ì¤˜ì•¼ í•œë‹¤.\n","<br><br>\n","í˜„ì¬ `Stacking`ì€ X, y ë°ì´í„°ë¥¼ í•˜ë‚˜ë¡œ ë¬¶ì€ numpy.ndarray ë°ì´í„°ë¥¼ ë°›ëŠ”ë‹¤ \n","\n","```python\n","# X, yê°€ í•˜ë‚˜ë¡œ ë¬¶ì¸ inputë§Œ í—ˆìš©í•œë‹¤\n","data = np.ndarray([[X1, y2],\n","                   [X2, y2],\n","                   ...\n","                   [Xn, yn]])\n","```"]},{"cell_type":"code","metadata":{"tags":[],"id":"xY3LBf1xWXH-"},"source":["from sklearn.model_selection import KFold\n","from sklearn.model_selection import StratifiedKFold\n","\n","class Stacking:\n","    def __init__(self, trainer):\n","        self.trainer = trainer\n","\n","\n","    def get_train_oof(self, args, data, fold_n=5, stratify=True):\n","\n","        oof = np.zeros(data.shape[0])\n","\n","        fold_models = []\n","\n","        if stratify:\n","            kfold = StratifiedKFold(n_splits=fold_n)\n","        else:\n","            kfold = KFold(n_splits=fold_n)\n","\n","        # í´ë˜ìŠ¤ ë¹„ìœ¨ ê³ ë ¤í•˜ì—¬ Foldë³„ë¡œ ë°ì´í„° ë‚˜ëˆ”\n","        target = self.trainer.get_target(data)\n","        for i, (train_index, valid_index) in enumerate(kfold.split(data, target)):\n","            train_data, valid_data = data[train_index], data[valid_index]\n","\n","            # ëª¨ë¸ ìƒì„± ë° í›ˆë ¨\n","            print(f'Calculating train oof {i + 1}')\n","            trained_model = self.trainer.train(args, train_data, valid_data)\n","\n","            # ëª¨ë¸ ê²€ì¦\n","            predict = self.trainer.evaluate(args, trained_model, valid_data)\n","            \n","            # foldë³„ oof ê°’ ëª¨ìœ¼ê¸°\n","            oof[valid_index] = predict\n","            fold_models.append(trained_model)\n","\n","        return oof, fold_models\n","\n","    def get_test_avg(self, args, models, test_data):\n","        predicts = np.zeros(test_data.shape[0])\n","\n","        # í´ë˜ìŠ¤ ë¹„ìœ¨ ê³ ë ¤í•˜ì—¬ Foldë³„ë¡œ ë°ì´í„° ë‚˜ëˆ”\n","        for i, model in enumerate(models):\n","            print(f'Calculating test avg {i + 1}')\n","            predict = self.trainer.test(args, model, test_data)\n","              \n","            # foldë³„ prediction ê°’ ëª¨ìœ¼ê¸°\n","            predicts += predict\n","\n","        # predictionë“¤ì˜ average ê³„ì‚°\n","        predict_avg = predicts / len(models)\n","\n","        return predict_avg\n","\n","\n","    def train_oof_stacking(self, args_list, data, fold_n=5, stratify=True):\n","    \n","        S_train = None\n","        models_list = []\n","        for i, args in enumerate(args_list):\n","            print(f'training oof stacking model [ {i + 1} ]')\n","            train_oof, models = self.get_train_oof(args, data, fold_n=fold_n, stratify=stratify)\n","            train_oof = train_oof.reshape(-1, 1)\n","\n","            # oof stack!\n","            if not isinstance(S_train, np.ndarray):\n","                S_train = train_oof\n","            else:\n","                S_train = np.concatenate([S_train, train_oof], axis=1)\n","\n","            # store fold models\n","            models_list.append(models)\n","\n","        return models_list, S_train\n","\n","    def test_avg_stacking(self, args, models_list, test_data):\n","    \n","        S_test = None\n","        for i, models in enumerate(models_list):\n","            print(f'test average stacking model [ {i + 1} ]')\n","            test_avg = self.get_test_avg(args, models, test_data)\n","            test_avg = test_avg.reshape(-1, 1)\n","\n","            # avg stack!\n","            if not isinstance(S_test, np.ndarray):\n","                S_test = test_avg\n","            else:\n","                S_test = np.concatenate([S_test, test_avg], axis=1)\n","\n","        return S_test\n","\n","\n","    def train(self, meta_model, args_list, data):\n","        models_list, S_train = self.train_oof_stacking(args_list, data)\n","        target = self.trainer.get_target(data)\n","        meta_model.fit(S_train, target)\n","        \n","        return meta_model, models_list, S_train, target\n","\n","    def test(self, meta_model, models_list, test_data):\n","        S_test = self.test_avg_stacking(args, models_list, test_data)\n","        predict = meta_model.predict(S_test)\n","\n","        return predict, S_test\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"tags":[],"id":"V3bEy2BNWXH-"},"source":["### oof stacking ì‚¬ìš©í•˜ê¸°\n","- args_list ì¤€ë¹„í•˜ê¸°\n","- ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n","- oof stacking ì§„í–‰í•˜ê¸°"]},{"cell_type":"markdown","metadata":{"id":"r-amXuKaWXH-"},"source":["#### ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°"]},{"cell_type":"code","metadata":{"id":"DVe-U8_2WXH-","outputId":"5d51ef3c-e29d-42d2-b0fb-d9e794a55180"},"source":["preprocess = Preprocess(args)\n","preprocess.load_train_data(file_name)\n","preprocess.load_test_data(test_file_name)\n","\n","data = preprocess.get_train_data()\n","test_data = preprocess.get_test_data()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:61: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"tags":[],"id":"LYFj53H8WXH_"},"source":["#### args_list\n","> ìì‹ ì´ ì‹¤í—˜ì„ ì§„í–‰í•˜ë©´ì„œ ê°€ì¥ ì¢‹ë‹¤ê³  ìƒê°í–ˆë˜ ì‹¤í—˜ ì„¸íŒ… ê°’(args)ë“¤ì„ ëª¨ì€ ë¦¬ìŠ¤íŠ¸ë‹¤"]},{"cell_type":"code","metadata":{"id":"X9qEM-qxWXH_"},"source":["# hidden_dimì´ ë‹¤ë¥¸ 3ê°œì˜ args\n","args_list = []\n","hidden_dim_list = [128, 256, 512]\n","\n","for hidden_dim in hidden_dim_list:\n","    copy_args = copy.deepcopy(args)\n","    copy_args.hidden_dim = hidden_dim\n","    args_list.append(copy_args)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FM60MXw1WXH_"},"source":["#### oof stacking ì‚¬ìš©í•˜ê¸°"]},{"cell_type":"code","metadata":{"tags":[],"id":"KMT-ZaM8WXH_","outputId":"a7240eaa-be81-418d-c77d-6304326d7b1e"},"source":["from sklearn.linear_model import LinearRegression\n","\n","# oof stacking ensemble\n","# Train\n","stacking = Stacking(Trainer())\n","meta_model = LinearRegression()\n","meta_model, models_list, S_train, target = stacking.train(meta_model, args_list, data)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["  0%|          | 0/20 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["training oof stacking model [ 1 ]\n","Calculating train oof 1\n","Training steps: 0 Loss: 0.6997650861740112\n","Training steps: 50 Loss: 0.6777464747428894\n","TRAIN AUC : 0.6814165486737522 ACC : 0.5390070921985816\n"],"name":"stdout"},{"output_type":"stream","text":["  5%|â–Œ         | 1/20 [00:01<00:25,  1.34s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7373135527408081 ACC : 0.6559701492537313\n","\n","Training steps: 0 Loss: 0.6763064861297607\n","Training steps: 50 Loss: 0.6480714082717896\n","TRAIN AUC : 0.7264773727184004 ACC : 0.6759985069055617\n"],"name":"stdout"},{"output_type":"stream","text":[" 10%|â–ˆ         | 2/20 [00:02<00:23,  1.32s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7474760999384088 ACC : 0.6835820895522388\n","\n","Training steps: 0 Loss: 0.6279779672622681\n","Training steps: 50 Loss: 0.637290358543396\n","TRAIN AUC : 0.7365658366963175 ACC : 0.6825307950727884\n"],"name":"stdout"},{"output_type":"stream","text":[" 15%|â–ˆâ–Œ        | 3/20 [00:03<00:22,  1.32s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.749301520142106 ACC : 0.6835820895522388\n","\n","Training steps: 0 Loss: 0.6074259281158447\n","Training steps: 50 Loss: 0.6667496562004089\n","TRAIN AUC : 0.7424269346557473 ACC : 0.6857036207540127\n"],"name":"stdout"},{"output_type":"stream","text":[" 20%|â–ˆâ–ˆ        | 4/20 [00:05<00:20,  1.30s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7512809183336457 ACC : 0.691044776119403\n","\n","Training steps: 0 Loss: 0.5085664987564087\n","Training steps: 50 Loss: 0.6156361699104309\n","TRAIN AUC : 0.7451172987290264 ACC : 0.6847704367301232\n"],"name":"stdout"},{"output_type":"stream","text":[" 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:06<00:19,  1.31s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7527091199600104 ACC : 0.6873134328358209\n","\n","Training steps: 0 Loss: 0.6320834159851074\n","Training steps: 50 Loss: 0.5945668816566467\n","TRAIN AUC : 0.747546575562737 ACC : 0.6855169839492348\n"],"name":"stdout"},{"output_type":"stream","text":[" 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:07<00:18,  1.30s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7536262931919414 ACC : 0.6940298507462687\n","\n","Training steps: 0 Loss: 0.568703293800354\n","Training steps: 50 Loss: 0.5592508316040039\n","TRAIN AUC : 0.7493592510167119 ACC : 0.6885031728256812\n"],"name":"stdout"},{"output_type":"stream","text":[" 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:09<00:16,  1.30s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7539788804684501 ACC : 0.6955223880597015\n","\n","Training steps: 0 Loss: 0.664838433265686\n","Training steps: 50 Loss: 0.6402775049209595\n","TRAIN AUC : 0.7508043385287437 ACC : 0.6886898096304591\n"],"name":"stdout"},{"output_type":"stream","text":[" 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:10<00:15,  1.29s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7540904587205098 ACC : 0.691044776119403\n","\n","Training steps: 0 Loss: 0.6378889083862305\n","Training steps: 50 Loss: 0.6180557012557983\n","TRAIN AUC : 0.7516060250085425 ACC : 0.6881298992161254\n"],"name":"stdout"},{"output_type":"stream","text":[" 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:11<00:14,  1.30s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7546528131108909 ACC : 0.6925373134328359\n","\n","Training steps: 0 Loss: 0.5937118530273438\n","Training steps: 50 Loss: 0.5628595352172852\n","TRAIN AUC : 0.7526029162488526 ACC : 0.6866368047779022\n"],"name":"stdout"},{"output_type":"stream","text":[" 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:12<00:12,  1.29s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.75459479241982 ACC : 0.6925373134328359\n","\n","Training steps: 0 Loss: 0.6048063635826111\n","Training steps: 50 Loss: 0.6130580306053162\n","TRAIN AUC : 0.7536465672995107 ACC : 0.6886898096304591\n"],"name":"stdout"},{"output_type":"stream","text":[" 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:14<00:11,  1.30s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7550299476028528 ACC : 0.6940298507462687\n","\n","Training steps: 0 Loss: 0.6081990003585815\n","Training steps: 50 Loss: 0.5760375261306763\n","TRAIN AUC : 0.7545417036092431 ACC : 0.6885031728256812\n"],"name":"stdout"},{"output_type":"stream","text":[" 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:15<00:10,  1.29s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7552932722777138 ACC : 0.6865671641791045\n","\n","Training steps: 0 Loss: 0.581610381603241\n","Training steps: 50 Loss: 0.6352672576904297\n","TRAIN AUC : 0.7546663499096629 ACC : 0.6905561776782382\n"],"name":"stdout"},{"output_type":"stream","text":[" 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:16<00:09,  1.30s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7553579876639085 ACC : 0.6895522388059702\n","\n","Training steps: 0 Loss: 0.6045230031013489\n","Training steps: 50 Loss: 0.6670162677764893\n","TRAIN AUC : 0.7556836200523933 ACC : 0.690742814483016\n"],"name":"stdout"},{"output_type":"stream","text":[" 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:18<00:07,  1.33s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7555097340867097 ACC : 0.6880597014925374\n","\n","Training steps: 0 Loss: 0.5726049542427063\n","Training steps: 50 Loss: 0.5767205953598022\n","TRAIN AUC : 0.7568279093814417 ACC : 0.6914893617021277\n"],"name":"stdout"},{"output_type":"stream","text":[" 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:19<00:06,  1.35s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7552553356720135 ACC : 0.6970149253731344\n","\n","Training steps: 0 Loss: 0.5688243508338928\n","Training steps: 50 Loss: 0.5350794792175293\n","TRAIN AUC : 0.7562428534260006 ACC : 0.690742814483016\n"],"name":"stdout"},{"output_type":"stream","text":[" 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:21<00:05,  1.35s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7553713770541556 ACC : 0.6947761194029851\n","\n","Training steps: 0 Loss: 0.5771316289901733\n","Training steps: 50 Loss: 0.575346052646637\n","TRAIN AUC : 0.7565202717038102 ACC : 0.6924225457260171\n"],"name":"stdout"},{"output_type":"stream","text":[" 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:22<00:04,  1.34s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7555967651233163 ACC : 0.6917910447761194\n","\n","Training steps: 0 Loss: 0.6099138855934143\n","Training steps: 50 Loss: 0.6519904136657715\n","TRAIN AUC : 0.7572204126253164 ACC : 0.6926091825307951\n"],"name":"stdout"},{"output_type":"stream","text":[" 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:23<00:02,  1.34s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7554695659159683 ACC : 0.6917910447761194\n","\n","Training steps: 0 Loss: 0.5361912846565247\n","Training steps: 50 Loss: 0.541312575340271\n","TRAIN AUC : 0.7566468023547961 ACC : 0.6963419186263531\n"],"name":"stdout"},{"output_type":"stream","text":[" 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:24<00:01,  1.32s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.755503039391586 ACC : 0.6925373134328359\n","\n","Training steps: 0 Loss: 0.5865407586097717\n","Training steps: 50 Loss: 0.5491001009941101\n","TRAIN AUC : 0.7577880906810908 ACC : 0.6911160880925719\n"],"name":"stdout"},{"output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:26<00:00,  1.31s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7559114157941248 ACC : 0.6962686567164179\n","\n","VALID AUC : 0.7559114157941248 ACC : 0.6962686567164179\n","\n","AUC : 0.7559114157941248, ACC : 0.6962686567164179\n","Calculating train oof 2\n"],"name":"stdout"},{"output_type":"stream","text":["\n","/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","  0%|          | 0/20 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Training steps: 0 Loss: 0.6878290772438049\n","Training steps: 50 Loss: 0.6814248561859131\n","TRAIN AUC : 0.7087147165825083 ACC : 0.6007838745800672\n"],"name":"stdout"},{"output_type":"stream","text":["  5%|â–Œ         | 1/20 [00:01<00:24,  1.31s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.71280985280597 ACC : 0.6694029850746268\n","\n","Training steps: 0 Loss: 0.6712976694107056\n","Training steps: 50 Loss: 0.6576353311538696\n","TRAIN AUC : 0.7358301024863377 ACC : 0.68682344158268\n"],"name":"stdout"},{"output_type":"stream","text":[" 10%|â–ˆ         | 2/20 [00:02<00:23,  1.30s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7160947165466084 ACC : 0.6753731343283582\n","\n","Training steps: 0 Loss: 0.5815505981445312\n","Training steps: 50 Loss: 0.671345591545105\n","TRAIN AUC : 0.7458375393899059 ACC : 0.6881298992161254\n"],"name":"stdout"},{"output_type":"stream","text":[" 15%|â–ˆâ–Œ        | 3/20 [00:03<00:21,  1.28s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7167106284979782 ACC : 0.6761194029850747\n","\n","Training steps: 0 Loss: 0.5864525437355042\n","Training steps: 50 Loss: 0.6183271408081055\n","TRAIN AUC : 0.7510785464315145 ACC : 0.6920492721164614\n"],"name":"stdout"},{"output_type":"stream","text":[" 20%|â–ˆâ–ˆ        | 4/20 [00:05<00:20,  1.27s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7172484356729061 ACC : 0.6776119402985075\n","\n","Training steps: 0 Loss: 0.5745105743408203\n","Training steps: 50 Loss: 0.5363160967826843\n","TRAIN AUC : 0.7531924388130433 ACC : 0.6944755505785741\n"],"name":"stdout"},{"output_type":"stream","text":[" 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:06<00:19,  1.27s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7176077176445385 ACC : 0.6783582089552239\n","\n","Training steps: 0 Loss: 0.6356727480888367\n","Training steps: 50 Loss: 0.630001962184906\n","TRAIN AUC : 0.7550629708084786 ACC : 0.6948488241881299\n"],"name":"stdout"},{"output_type":"stream","text":[" 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:07<00:17,  1.27s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.718027251872283 ACC : 0.6776119402985075\n","\n","Training steps: 0 Loss: 0.6779297590255737\n","Training steps: 50 Loss: 0.6206744313240051\n","TRAIN AUC : 0.7564221458928416 ACC : 0.6967151922359089\n"],"name":"stdout"},{"output_type":"stream","text":[" 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:08<00:16,  1.27s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7184021547992038 ACC : 0.6798507462686567\n","\n","Training steps: 0 Loss: 0.6240317821502686\n","Training steps: 50 Loss: 0.6181078553199768\n","TRAIN AUC : 0.7579350002344969 ACC : 0.6985815602836879\n"],"name":"stdout"},{"output_type":"stream","text":[" 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:10<00:15,  1.28s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7183240500227619 ACC : 0.6783582089552239\n","\n","Training steps: 0 Loss: 0.5224050283432007\n","Training steps: 50 Loss: 0.6515611410140991\n","TRAIN AUC : 0.7598075561620217 ACC : 0.700447928331467\n"],"name":"stdout"},{"output_type":"stream","text":[" 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:11<00:14,  1.28s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7186096903480349 ACC : 0.6761194029850747\n","\n","Training steps: 0 Loss: 0.5710797309875488\n","Training steps: 50 Loss: 0.594196081161499\n","TRAIN AUC : 0.7608738194194749 ACC : 0.7008212019410228\n"],"name":"stdout"},{"output_type":"stream","text":[" 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:12<00:12,  1.28s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.718495880530934 ACC : 0.6723880597014925\n","\n","Training steps: 0 Loss: 0.5302597284317017\n","Training steps: 50 Loss: 0.5611529350280762\n","TRAIN AUC : 0.7610161925733696 ACC : 0.700261291526689\n"],"name":"stdout"},{"output_type":"stream","text":[" 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:13<00:11,  1.28s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7180763463031894 ACC : 0.676865671641791\n","\n","Training steps: 0 Loss: 0.5704604387283325\n","Training steps: 50 Loss: 0.6150501370429993\n","TRAIN AUC : 0.7628816298431997 ACC : 0.6997013811123554\n"],"name":"stdout"},{"output_type":"stream","text":[" 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:15<00:10,  1.28s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7183976916691214 ACC : 0.6738805970149254\n","\n","Training steps: 0 Loss: 0.5732660293579102\n","Training steps: 50 Loss: 0.49876075983047485\n","TRAIN AUC : 0.7628777913513054 ACC : 0.7019410227696902\n"],"name":"stdout"},{"output_type":"stream","text":[" 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:16<00:09,  1.29s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7183106606325148 ACC : 0.6716417910447762\n","\n","Training steps: 0 Loss: 0.6327087879180908\n","Training steps: 50 Loss: 0.5558061599731445\n","TRAIN AUC : 0.7633080513972668 ACC : 0.6989548338932438\n"],"name":"stdout"},{"output_type":"stream","text":[" 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:17<00:09,  1.38s/it]\n","/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","  0%|          | 0/20 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7183820707138331 ACC : 0.6723880597014925\n","\n","EarlyStopping counter: 5 out of 5\n","VALID AUC : 0.7186096903480349 ACC : 0.6761194029850747\n","\n","AUC : 0.7186096903480349, ACC : 0.6761194029850747\n","Calculating train oof 3\n","Training steps: 0 Loss: 0.6898563504219055\n","Training steps: 50 Loss: 0.669777512550354\n","TRAIN AUC : 0.6962870058534908 ACC : 0.5548712206047033\n"],"name":"stdout"},{"output_type":"stream","text":["  5%|â–Œ         | 1/20 [00:01<00:23,  1.25s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7426246775388516 ACC : 0.667910447761194\n","\n","Training steps: 0 Loss: 0.6765454411506653\n","Training steps: 50 Loss: 0.6339840292930603\n","TRAIN AUC : 0.7278730483711394 ACC : 0.6758118701007839\n"],"name":"stdout"},{"output_type":"stream","text":[" 10%|â–ˆ         | 2/20 [00:02<00:22,  1.27s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7461460871738567 ACC : 0.6902985074626866\n","\n","Training steps: 0 Loss: 0.5718581676483154\n","Training steps: 50 Loss: 0.5861855745315552\n","TRAIN AUC : 0.7389161801785303 ACC : 0.6855169839492348\n"],"name":"stdout"},{"output_type":"stream","text":[" 15%|â–ˆâ–Œ        | 3/20 [00:03<00:22,  1.31s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7480317596336663 ACC : 0.6955223880597015\n","\n","Training steps: 0 Loss: 0.5482975840568542\n","Training steps: 50 Loss: 0.5333051681518555\n","TRAIN AUC : 0.7422127468080497 ACC : 0.687010078387458\n"],"name":"stdout"},{"output_type":"stream","text":[" 20%|â–ˆâ–ˆ        | 4/20 [00:05<00:21,  1.32s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7499866106097529 ACC : 0.6970149253731344\n","\n","Training steps: 0 Loss: 0.5837146043777466\n","Training steps: 50 Loss: 0.5854309797286987\n","TRAIN AUC : 0.7457275491494461 ACC : 0.6903695408734603\n"],"name":"stdout"},{"output_type":"stream","text":[" 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:06<00:19,  1.31s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7509216363620135 ACC : 0.7022388059701492\n","\n","Training steps: 0 Loss: 0.629287600517273\n","Training steps: 50 Loss: 0.5598567724227905\n","TRAIN AUC : 0.7472213506131538 ACC : 0.6909294512877939\n"],"name":"stdout"},{"output_type":"stream","text":[" 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:07<00:18,  1.31s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7518321148988208 ACC : 0.7022388059701492\n","\n","Training steps: 0 Loss: 0.597134530544281\n","Training steps: 50 Loss: 0.5760419368743896\n","TRAIN AUC : 0.7487596785828344 ACC : 0.6935423665546846\n"],"name":"stdout"},{"output_type":"stream","text":[" 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:09<00:16,  1.30s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7528206982120701 ACC : 0.7029850746268657\n","\n","Training steps: 0 Loss: 0.6471681594848633\n","Training steps: 50 Loss: 0.6922041177749634\n","TRAIN AUC : 0.750748575710135 ACC : 0.6942889137737962\n"],"name":"stdout"},{"output_type":"stream","text":[" 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:10<00:15,  1.31s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7534343785983986 ACC : 0.7\n","\n","Training steps: 0 Loss: 0.6290220022201538\n","Training steps: 50 Loss: 0.5210558772087097\n","TRAIN AUC : 0.7515170417873582 ACC : 0.6952220977976857\n"],"name":"stdout"},{"output_type":"stream","text":[" 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:11<00:14,  1.32s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7540726062001804 ACC : 0.7029850746268657\n","\n","Training steps: 0 Loss: 0.5601211786270142\n","Training steps: 50 Loss: 0.5514159798622131\n","TRAIN AUC : 0.753684952218453 ACC : 0.6982082866741322\n"],"name":"stdout"},{"output_type":"stream","text":[" 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:13<00:13,  1.31s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7547331494523739 ACC : 0.6962686567164179\n","\n","Training steps: 0 Loss: 0.6447880864143372\n","Training steps: 50 Loss: 0.6004681587219238\n","TRAIN AUC : 0.7537850321707497 ACC : 0.6972751026502426\n"],"name":"stdout"},{"output_type":"stream","text":[" 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:14<00:11,  1.30s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7551995465459835 ACC : 0.6955223880597015\n","\n","Training steps: 0 Loss: 0.5123804807662964\n","Training steps: 50 Loss: 0.5826216340065002\n","TRAIN AUC : 0.7554584750551068 ACC : 0.6987681970884658\n"],"name":"stdout"},{"output_type":"stream","text":[" 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:15<00:10,  1.28s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7558020691071061 ACC : 0.6970149253731344\n","\n","Training steps: 0 Loss: 0.5648361444473267\n","Training steps: 50 Loss: 0.5326249599456787\n","TRAIN AUC : 0.7563946483327266 ACC : 0.6998880179171333\n"],"name":"stdout"},{"output_type":"stream","text":[" 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:16<00:08,  1.28s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7561881298592328 ACC : 0.6962686567164179\n","\n","Training steps: 0 Loss: 0.5406912565231323\n","Training steps: 50 Loss: 0.6097453832626343\n","TRAIN AUC : 0.7564719764967047 ACC : 0.700261291526689\n"],"name":"stdout"},{"output_type":"stream","text":[" 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:18<00:07,  1.28s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7561948245543564 ACC : 0.6992537313432836\n","\n","Training steps: 0 Loss: 0.6151050329208374\n","Training steps: 50 Loss: 0.5475364923477173\n","TRAIN AUC : 0.7574071727036605 ACC : 0.7019410227696902\n"],"name":"stdout"},{"output_type":"stream","text":[" 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:19<00:06,  1.27s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7566500638227602 ACC : 0.6977611940298507\n","\n","Training steps: 0 Loss: 0.6462013125419617\n","Training steps: 50 Loss: 0.518279492855072\n","TRAIN AUC : 0.7577691075939048 ACC : 0.7028742067935797\n"],"name":"stdout"},{"output_type":"stream","text":[" 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:20<00:05,  1.27s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7570249667496809 ACC : 0.6940298507462687\n","\n","Training steps: 0 Loss: 0.5695333480834961\n","Training steps: 50 Loss: 0.577911376953125\n","TRAIN AUC : 0.7586938351866037 ACC : 0.7032474804031354\n"],"name":"stdout"},{"output_type":"stream","text":[" 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:22<00:03,  1.27s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7573552383757778 ACC : 0.6932835820895522\n","\n","Training steps: 0 Loss: 0.5675778388977051\n","Training steps: 50 Loss: 0.5619768500328064\n","TRAIN AUC : 0.758299656964448 ACC : 0.7045539380365808\n"],"name":"stdout"},{"output_type":"stream","text":[" 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:23<00:02,  1.28s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.757346312115613 ACC : 0.6932835820895522\n","\n","Training steps: 0 Loss: 0.6112231016159058\n","Training steps: 50 Loss: 0.6407561898231506\n","TRAIN AUC : 0.7586482618192051 ACC : 0.7015677491601344\n"],"name":"stdout"},{"output_type":"stream","text":[" 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:24<00:01,  1.28s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7573775540261897 ACC : 0.6902985074626866\n","\n","Training steps: 0 Loss: 0.6560541391372681\n","Training steps: 50 Loss: 0.5915330648422241\n","TRAIN AUC : 0.7597145250766582 ACC : 0.7069802164986936\n"],"name":"stdout"},{"output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:25<00:00,  1.29s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7574757428880021 ACC : 0.6895522388059702\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","  0%|          | 0/20 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7574757428880021 ACC : 0.6895522388059702\n","\n","AUC : 0.7574757428880021, ACC : 0.6895522388059702\n","Calculating train oof 4\n","Training steps: 0 Loss: 0.7001155614852905\n","Training steps: 50 Loss: 0.6808075904846191\n","TRAIN AUC : 0.6883724632569208 ACC : 0.6057100205262176\n"],"name":"stdout"},{"output_type":"stream","text":["  5%|â–Œ         | 1/20 [00:01<00:24,  1.28s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7250870550581336 ACC : 0.6631814787154593\n","\n","Training steps: 0 Loss: 0.6642827987670898\n","Training steps: 50 Loss: 0.619153618812561\n","TRAIN AUC : 0.7313625914321401 ACC : 0.6838962493002426\n"],"name":"stdout"},{"output_type":"stream","text":[" 10%|â–ˆ         | 2/20 [00:02<00:23,  1.29s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7299549861650626 ACC : 0.6669156086631814\n","\n","Training steps: 0 Loss: 0.5707974433898926\n","Training steps: 50 Loss: 0.6209926605224609\n","TRAIN AUC : 0.744523419910859 ACC : 0.6902407165515955\n"],"name":"stdout"},{"output_type":"stream","text":[" 15%|â–ˆâ–Œ        | 3/20 [00:04<00:23,  1.35s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7304288160065084 ACC : 0.6676624346527259\n","\n","Training steps: 0 Loss: 0.6039087772369385\n","Training steps: 50 Loss: 0.5912145972251892\n","TRAIN AUC : 0.7467685512505539 ACC : 0.6945325620451577\n"],"name":"stdout"},{"output_type":"stream","text":[" 20%|â–ˆâ–ˆ        | 4/20 [00:05<00:22,  1.38s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7318592457165335 ACC : 0.6669156086631814\n","\n","Training steps: 0 Loss: 0.6276885271072388\n","Training steps: 50 Loss: 0.6335732936859131\n","TRAIN AUC : 0.7491437916558301 ACC : 0.6952789699570815\n"],"name":"stdout"},{"output_type":"stream","text":[" 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:07<00:21,  1.41s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7329231278133647 ACC : 0.6676624346527259\n","\n","Training steps: 0 Loss: 0.578344464302063\n","Training steps: 50 Loss: 0.5598247647285461\n","TRAIN AUC : 0.7517987142294251 ACC : 0.697891397648815\n"],"name":"stdout"},{"output_type":"stream","text":[" 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:08<00:18,  1.35s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7338171463821304 ACC : 0.666168782673637\n","\n","Training steps: 0 Loss: 0.556313157081604\n","Training steps: 50 Loss: 0.6708709001541138\n","TRAIN AUC : 0.7540623329162403 ACC : 0.698264601604777\n"],"name":"stdout"},{"output_type":"stream","text":[" 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:09<00:17,  1.32s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7338998430997412 ACC : 0.6684092606422704\n","\n","Training steps: 0 Loss: 0.6249856352806091\n","Training steps: 50 Loss: 0.5210883021354675\n","TRAIN AUC : 0.7550947640484305 ACC : 0.7012502332524725\n"],"name":"stdout"},{"output_type":"stream","text":[" 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:10<00:15,  1.31s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7346508186975044 ACC : 0.666168782673637\n","\n","Training steps: 0 Loss: 0.5494244694709778\n","Training steps: 50 Loss: 0.6054794788360596\n","TRAIN AUC : 0.754453218221576 ACC : 0.698637805560739\n"],"name":"stdout"},{"output_type":"stream","text":[" 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:12<00:14,  1.31s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7348072719470384 ACC : 0.6699029126213593\n","\n","Training steps: 0 Loss: 0.6148191690444946\n","Training steps: 50 Loss: 0.6407634019851685\n","TRAIN AUC : 0.7563861575674502 ACC : 0.7003172233625676\n"],"name":"stdout"},{"output_type":"stream","text":[" 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:13<00:13,  1.30s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7350330116356517 ACC : 0.6639283047050037\n","\n","Training steps: 0 Loss: 0.5524371862411499\n","Training steps: 50 Loss: 0.6508289575576782\n","TRAIN AUC : 0.75770329384529 ACC : 0.7027430490763202\n"],"name":"stdout"},{"output_type":"stream","text":[" 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:14<00:11,  1.30s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7355940082875521 ACC : 0.6646751306945482\n","\n","Training steps: 0 Loss: 0.571931779384613\n","Training steps: 50 Loss: 0.602794349193573\n","TRAIN AUC : 0.7584511593589788 ACC : 0.7021832431423773\n"],"name":"stdout"},{"output_type":"stream","text":[" 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:15<00:10,  1.30s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7353995592488456 ACC : 0.6691560866318148\n","\n","Training steps: 0 Loss: 0.5821197628974915\n","Training steps: 50 Loss: 0.7247809171676636\n","TRAIN AUC : 0.7581517340992072 ACC : 0.7012502332524725\n"],"name":"stdout"},{"output_type":"stream","text":[" 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:17<00:09,  1.35s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7354107344809551 ACC : 0.6646751306945482\n","\n","Training steps: 0 Loss: 0.5318681001663208\n","Training steps: 50 Loss: 0.6049379110336304\n","TRAIN AUC : 0.7589735490013763 ACC : 0.7008770292965105\n"],"name":"stdout"},{"output_type":"stream","text":[" 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:18<00:08,  1.35s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7356655297730534 ACC : 0.6631814787154593\n","\n","Training steps: 0 Loss: 0.695160984992981\n","Training steps: 50 Loss: 0.7194032073020935\n","TRAIN AUC : 0.7596339309932212 ACC : 0.7008770292965105\n"],"name":"stdout"},{"output_type":"stream","text":[" 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:20<00:06,  1.34s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.735390619063158 ACC : 0.6624346527259148\n","\n","Training steps: 0 Loss: 0.6593572497367859\n","Training steps: 50 Loss: 0.6403828263282776\n","TRAIN AUC : 0.7598933119614949 ACC : 0.7029296510543012\n"],"name":"stdout"},{"output_type":"stream","text":[" 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:21<00:05,  1.32s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7360633680361541 ACC : 0.6624346527259148\n","\n","Training steps: 0 Loss: 0.5809147357940674\n","Training steps: 50 Loss: 0.4622341990470886\n","TRAIN AUC : 0.7600303973844799 ACC : 0.7018100391864154\n"],"name":"stdout"},{"output_type":"stream","text":[" 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:22<00:03,  1.32s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7362131161464224 ACC : 0.6654219566840927\n","\n","Training steps: 0 Loss: 0.5401442646980286\n","Training steps: 50 Loss: 0.658587634563446\n","TRAIN AUC : 0.7609538578140226 ACC : 0.7023698451203583\n"],"name":"stdout"},{"output_type":"stream","text":[" 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:23<00:02,  1.32s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.736143829707343 ACC : 0.6624346527259148\n","\n","Training steps: 0 Loss: 0.5333014130592346\n","Training steps: 50 Loss: 0.5848897695541382\n","TRAIN AUC : 0.7608102146150781 ACC : 0.7029296510543012\n"],"name":"stdout"},{"output_type":"stream","text":[" 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:25<00:01,  1.29s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7365573132953971 ACC : 0.6639283047050037\n","\n","Training steps: 0 Loss: 0.5164567232131958\n","Training steps: 50 Loss: 0.5481745004653931\n","TRAIN AUC : 0.7606770359522393 ACC : 0.7001306213845867\n"],"name":"stdout"},{"output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:26<00:00,  1.33s/it]\n","/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","  0%|          | 0/20 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.736613189455945 ACC : 0.6646751306945482\n","\n","VALID AUC : 0.736613189455945 ACC : 0.6646751306945482\n","\n","AUC : 0.736613189455945, ACC : 0.6646751306945482\n","Calculating train oof 5\n","Training steps: 0 Loss: 0.6948971748352051\n","Training steps: 50 Loss: 0.6780475974082947\n","TRAIN AUC : 0.6856509164701194 ACC : 0.6241836163463332\n"],"name":"stdout"},{"output_type":"stream","text":["  5%|â–Œ         | 1/20 [00:01<00:25,  1.32s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7558569391486261 ACC : 0.6990291262135923\n","\n","Training steps: 0 Loss: 0.6707037687301636\n","Training steps: 50 Loss: 0.6378798484802246\n","TRAIN AUC : 0.7249086236707248 ACC : 0.6805374136965852\n"],"name":"stdout"},{"output_type":"stream","text":[" 10%|â–ˆ         | 2/20 [00:02<00:23,  1.30s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7548645785372963 ACC : 0.6975354742345033\n","\n","Training steps: 0 Loss: 0.610081672668457\n","Training steps: 50 Loss: 0.6470378041267395\n","TRAIN AUC : 0.7410032894920431 ACC : 0.6812838216085091\n"],"name":"stdout"},{"output_type":"stream","text":[" 15%|â–ˆâ–Œ        | 3/20 [00:03<00:21,  1.28s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7559698089929329 ACC : 0.6997759522031367\n","\n","Training steps: 0 Loss: 0.5977480411529541\n","Training steps: 50 Loss: 0.6353902816772461\n","TRAIN AUC : 0.7437579739765126 ACC : 0.6838962493002426\n"],"name":"stdout"},{"output_type":"stream","text":[" 20%|â–ˆâ–ˆ        | 4/20 [00:05<00:20,  1.29s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7578818912068802 ACC : 0.6923076923076923\n","\n","Training steps: 0 Loss: 0.5761646032333374\n","Training steps: 50 Loss: 0.6092183589935303\n","TRAIN AUC : 0.746975679301873 ACC : 0.6887479007277477\n"],"name":"stdout"},{"output_type":"stream","text":[" 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:06<00:19,  1.30s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.758697683150879 ACC : 0.6975354742345033\n","\n","Training steps: 0 Loss: 0.5904600620269775\n","Training steps: 50 Loss: 0.6073126196861267\n","TRAIN AUC : 0.7485404065039742 ACC : 0.6898675125956335\n"],"name":"stdout"},{"output_type":"stream","text":[" 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:07<00:18,  1.30s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7595939367660666 ACC : 0.700522778192681\n","\n","Training steps: 0 Loss: 0.6412653923034668\n","Training steps: 50 Loss: 0.5880030393600464\n","TRAIN AUC : 0.7508472088431191 ACC : 0.6908005224855384\n"],"name":"stdout"},{"output_type":"stream","text":[" 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:09<00:16,  1.30s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7585591102727204 ACC : 0.6990291262135923\n","\n","Training steps: 0 Loss: 0.6266379356384277\n","Training steps: 50 Loss: 0.5737100839614868\n","TRAIN AUC : 0.7520310966945459 ACC : 0.6891211046837097\n"],"name":"stdout"},{"output_type":"stream","text":[" 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:10<00:15,  1.29s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7593525517524998 ACC : 0.7035100821508589\n","\n","Training steps: 0 Loss: 0.4913884401321411\n","Training steps: 50 Loss: 0.5324468612670898\n","TRAIN AUC : 0.7534248333766798 ACC : 0.6913603284194813\n"],"name":"stdout"},{"output_type":"stream","text":[" 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:11<00:14,  1.29s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7591938634565439 ACC : 0.6982823002240478\n","\n","Training steps: 0 Loss: 0.5617920756340027\n","Training steps: 50 Loss: 0.5890271663665771\n","TRAIN AUC : 0.7533132116582187 ACC : 0.6911737264415003\n"],"name":"stdout"},{"output_type":"stream","text":[" 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:12<00:12,  1.28s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7594620690271736 ACC : 0.6967886482449589\n","\n","Training steps: 0 Loss: 0.5837404727935791\n","Training steps: 50 Loss: 0.562797486782074\n","TRAIN AUC : 0.7551447845310157 ACC : 0.6902407165515955\n"],"name":"stdout"},{"output_type":"stream","text":[" 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:14<00:11,  1.28s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7599202535436662 ACC : 0.7035100821508589\n","\n","Training steps: 0 Loss: 0.6146731972694397\n","Training steps: 50 Loss: 0.5491130948066711\n","TRAIN AUC : 0.7564669437861864 ACC : 0.6913603284194813\n"],"name":"stdout"},{"output_type":"stream","text":[" 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:15<00:10,  1.28s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7593816073559847 ACC : 0.7050037341299478\n","\n","Training steps: 0 Loss: 0.5420964956283569\n","Training steps: 50 Loss: 0.5041060447692871\n","TRAIN AUC : 0.7563936920334463 ACC : 0.692666542265348\n"],"name":"stdout"},{"output_type":"stream","text":[" 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:16<00:09,  1.30s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7587379139864735 ACC : 0.7027632561613144\n","\n","Training steps: 0 Loss: 0.5557084083557129\n","Training steps: 50 Loss: 0.5636480450630188\n","TRAIN AUC : 0.7568461088110836 ACC : 0.692853144243329\n"],"name":"stdout"},{"output_type":"stream","text":[" 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:18<00:08,  1.36s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7595581760233161 ACC : 0.7050037341299478\n","\n","Training steps: 0 Loss: 0.6012765765190125\n","Training steps: 50 Loss: 0.6801983118057251\n","TRAIN AUC : 0.7564341549063885 ACC : 0.6941593580891957\n"],"name":"stdout"},{"output_type":"stream","text":[" 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:19<00:07,  1.40s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7599895399827453 ACC : 0.7042569081404033\n","\n","Training steps: 0 Loss: 0.6218613982200623\n","Training steps: 50 Loss: 0.6304099559783936\n","TRAIN AUC : 0.7582623791276317 ACC : 0.6965851838029483\n"],"name":"stdout"},{"output_type":"stream","text":[" 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:21<00:05,  1.46s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7591111667389332 ACC : 0.7042569081404033\n","\n","Training steps: 0 Loss: 0.46542370319366455\n","Training steps: 50 Loss: 0.5702555775642395\n","TRAIN AUC : 0.7582664951784999 ACC : 0.6937861541332339\n"],"name":"stdout"},{"output_type":"stream","text":[" 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:22<00:04,  1.48s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7595246503269873 ACC : 0.7042569081404033\n","\n","Training steps: 0 Loss: 0.6422139406204224\n","Training steps: 50 Loss: 0.4845152497291565\n","TRAIN AUC : 0.7583340960817428 ACC : 0.6943459600671767\n"],"name":"stdout"},{"output_type":"stream","text":[" 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:24<00:03,  1.51s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7592385643849822 ACC : 0.7035100821508589\n","\n","Training steps: 0 Loss: 0.5275359153747559\n","Training steps: 50 Loss: 0.6068345308303833\n","TRAIN AUC : 0.7590851707198374 ACC : 0.6958387758910245\n"],"name":"stdout"},{"output_type":"stream","text":[" 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:25<00:01,  1.46s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7597861507583512 ACC : 0.70201643017177\n","\n","Training steps: 0 Loss: 0.6248593926429749\n","Training steps: 50 Loss: 0.570500373840332\n","TRAIN AUC : 0.7589569452707552 ACC : 0.6939727561112148\n"],"name":"stdout"},{"output_type":"stream","text":[" 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:27<00:01,  1.42s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7594128980058915 ACC : 0.7050037341299478\n","\n","EarlyStopping counter: 5 out of 5\n","VALID AUC : 0.7599895399827453 ACC : 0.7042569081404033\n","\n","AUC : 0.7599895399827453, ACC : 0.7042569081404033\n","training oof stacking model [ 2 ]\n","Calculating train oof 1\n"],"name":"stdout"},{"output_type":"stream","text":["\n","/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","  0%|          | 0/20 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Training steps: 0 Loss: 0.692684531211853\n","Training steps: 50 Loss: 0.6650049686431885\n","TRAIN AUC : 0.7060767653712756 ACC : 0.6636804777902202\n"],"name":"stdout"},{"output_type":"stream","text":["  5%|â–Œ         | 1/20 [00:01<00:25,  1.35s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7510845406100206 ACC : 0.6955223880597015\n","\n","Training steps: 0 Loss: 0.6462497711181641\n","Training steps: 50 Loss: 0.6007921695709229\n","TRAIN AUC : 0.7367135139481026 ACC : 0.6845837999253452\n"],"name":"stdout"},{"output_type":"stream","text":[" 10%|â–ˆ         | 2/20 [00:02<00:24,  1.36s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7558623213632184 ACC : 0.6955223880597015\n","\n","Training steps: 0 Loss: 0.6003338694572449\n","Training steps: 50 Loss: 0.6163285970687866\n","TRAIN AUC : 0.748592180754723 ACC : 0.6920492721164614\n"],"name":"stdout"},{"output_type":"stream","text":[" 15%|â–ˆâ–Œ        | 3/20 [00:04<00:23,  1.37s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7590445331119622 ACC : 0.7007462686567164\n","\n","Training steps: 0 Loss: 0.5967324376106262\n","Training steps: 50 Loss: 0.5881352424621582\n","TRAIN AUC : 0.7565262039185559 ACC : 0.6974617394550205\n"],"name":"stdout"},{"output_type":"stream","text":[" 20%|â–ˆâ–ˆ        | 4/20 [00:05<00:21,  1.37s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7607918485392176 ACC : 0.6992537313432836\n","\n","Training steps: 0 Loss: 0.6922005414962769\n","Training steps: 50 Loss: 0.6116822957992554\n","TRAIN AUC : 0.7613757545777157 ACC : 0.700447928331467\n"],"name":"stdout"},{"output_type":"stream","text":[" 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:06<00:20,  1.38s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7619455676655152 ACC : 0.7052238805970149\n","\n","Training steps: 0 Loss: 0.6018722653388977\n","Training steps: 50 Loss: 0.5907625555992126\n","TRAIN AUC : 0.7646123709429233 ACC : 0.704180664427025\n"],"name":"stdout"},{"output_type":"stream","text":[" 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:08<00:19,  1.39s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7615862856938829 ACC : 0.7111940298507463\n","\n","Training steps: 0 Loss: 0.5216279625892639\n","Training steps: 50 Loss: 0.5634077787399292\n","TRAIN AUC : 0.7679278508688671 ACC : 0.707913400522583\n"],"name":"stdout"},{"output_type":"stream","text":[" 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:09<00:18,  1.39s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7615996750841301 ACC : 0.7111940298507463\n","\n","Training steps: 0 Loss: 0.6357064247131348\n","Training steps: 50 Loss: 0.5402825474739075\n","TRAIN AUC : 0.7703351436126378 ACC : 0.7112728630085853\n"],"name":"stdout"},{"output_type":"stream","text":[" 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:11<00:16,  1.38s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7620125146167511 ACC : 0.7119402985074627\n","\n","Training steps: 0 Loss: 0.5970004200935364\n","Training steps: 50 Loss: 0.49213528633117676\n","TRAIN AUC : 0.771716442368464 ACC : 0.7081000373273609\n"],"name":"stdout"},{"output_type":"stream","text":[" 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:12<00:14,  1.36s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.760912353051442 ACC : 0.7111940298507463\n","\n","Training steps: 0 Loss: 0.562271237373352\n","Training steps: 50 Loss: 0.5440491437911987\n","TRAIN AUC : 0.7733282600102286 ACC : 0.7120194102276969\n"],"name":"stdout"},{"output_type":"stream","text":[" 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:13<00:13,  1.36s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.761380981710093 ACC : 0.7089552238805971\n","\n","Training steps: 0 Loss: 0.5776056051254272\n","Training steps: 50 Loss: 0.5429163575172424\n","TRAIN AUC : 0.7746192495203978 ACC : 0.7114594998133632\n"],"name":"stdout"},{"output_type":"stream","text":[" 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:15<00:12,  1.37s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7603857037017201 ACC : 0.7044776119402985\n","\n","Training steps: 0 Loss: 0.6771318912506104\n","Training steps: 50 Loss: 0.5959485769271851\n","TRAIN AUC : 0.7761734897837491 ACC : 0.7144456886898096\n"],"name":"stdout"},{"output_type":"stream","text":[" 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:16<00:11,  1.38s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7605508395147684 ACC : 0.7052238805970149\n","\n","Training steps: 0 Loss: 0.5979354381561279\n","Training steps: 50 Loss: 0.48670750856399536\n","TRAIN AUC : 0.7763859328624039 ACC : 0.7123926838372527\n"],"name":"stdout"},{"output_type":"stream","text":[" 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:17<00:11,  1.50s/it]\n","/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","  0%|          | 0/20 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7604928188236975 ACC : 0.7097014925373134\n","\n","EarlyStopping counter: 5 out of 5\n","VALID AUC : 0.7620125146167511 ACC : 0.7119402985074627\n","\n","AUC : 0.7620125146167511, ACC : 0.7119402985074627\n","Calculating train oof 2\n","Training steps: 0 Loss: 0.6910948753356934\n","Training steps: 50 Loss: 0.6635079979896545\n","TRAIN AUC : 0.7143090044599087 ACC : 0.6384845091452034\n"],"name":"stdout"},{"output_type":"stream","text":["  5%|â–Œ         | 1/20 [00:01<00:25,  1.35s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7188685518928135 ACC : 0.6701492537313433\n","\n","Training steps: 0 Loss: 0.6044086217880249\n","Training steps: 50 Loss: 0.6349729299545288\n","TRAIN AUC : 0.7468773519486698 ACC : 0.6901829040686823\n"],"name":"stdout"},{"output_type":"stream","text":[" 10%|â–ˆ         | 2/20 [00:02<00:24,  1.36s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7201650911817475 ACC : 0.6694029850746268\n","\n","Training steps: 0 Loss: 0.5584808588027954\n","Training steps: 50 Loss: 0.5893946886062622\n","TRAIN AUC : 0.7560087054204532 ACC : 0.6942889137737962\n"],"name":"stdout"},{"output_type":"stream","text":[" 15%|â–ˆâ–Œ        | 3/20 [00:04<00:23,  1.36s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7208769604298888 ACC : 0.667910447761194\n","\n","Training steps: 0 Loss: 0.6196630001068115\n","Training steps: 50 Loss: 0.6256864666938782\n","TRAIN AUC : 0.7600176263547783 ACC : 0.7017543859649122\n"],"name":"stdout"},{"output_type":"stream","text":[" 20%|â–ˆâ–ˆ        | 4/20 [00:05<00:21,  1.36s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.722394424657901 ACC : 0.6686567164179105\n","\n","Training steps: 0 Loss: 0.6204932928085327\n","Training steps: 50 Loss: 0.5453636646270752\n","TRAIN AUC : 0.7634497266435445 ACC : 0.6995147443075774\n"],"name":"stdout"},{"output_type":"stream","text":[" 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:06<00:20,  1.35s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7227135384587919 ACC : 0.6701492537313433\n","\n","Training steps: 0 Loss: 0.5691058039665222\n","Training steps: 50 Loss: 0.5715482234954834\n","TRAIN AUC : 0.7684764062559322 ACC : 0.7077267637178052\n"],"name":"stdout"},{"output_type":"stream","text":[" 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:08<00:18,  1.34s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7230304206946415 ACC : 0.6649253731343283\n","\n","Training steps: 0 Loss: 0.5560972094535828\n","Training steps: 50 Loss: 0.5490104556083679\n","TRAIN AUC : 0.7709810571122928 ACC : 0.7077267637178052\n"],"name":"stdout"},{"output_type":"stream","text":[" 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:09<00:17,  1.35s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7238181631541833 ACC : 0.6656716417910448\n","\n","Training steps: 0 Loss: 0.5804452896118164\n","Training steps: 50 Loss: 0.5335571765899658\n","TRAIN AUC : 0.7718239201415021 ACC : 0.7092198581560284\n"],"name":"stdout"},{"output_type":"stream","text":[" 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:10<00:16,  1.36s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7243091074632462 ACC : 0.6716417910447762\n","\n","Training steps: 0 Loss: 0.6572000980377197\n","Training steps: 50 Loss: 0.6478089690208435\n","TRAIN AUC : 0.7742775539510504 ACC : 0.7114594998133632\n"],"name":"stdout"},{"output_type":"stream","text":[" 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:12<00:15,  1.37s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7234254077069331 ACC : 0.6753731343283582\n","\n","Training steps: 0 Loss: 0.6231088638305664\n","Training steps: 50 Loss: 0.6131117343902588\n","TRAIN AUC : 0.776046051852861 ACC : 0.7110862262038073\n"],"name":"stdout"},{"output_type":"stream","text":[" 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:13<00:13,  1.37s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7241328138249918 ACC : 0.667910447761194\n","\n","Training steps: 0 Loss: 0.48722603917121887\n","Training steps: 50 Loss: 0.6004788279533386\n","TRAIN AUC : 0.7769389548582187 ACC : 0.7105263157894737\n"],"name":"stdout"},{"output_type":"stream","text":[" 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:15<00:12,  1.38s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7254851422399557 ACC : 0.6708955223880597\n","\n","Training steps: 0 Loss: 0.6360686421394348\n","Training steps: 50 Loss: 0.48598557710647583\n","TRAIN AUC : 0.7779930745231336 ACC : 0.7107129525942516\n"],"name":"stdout"},{"output_type":"stream","text":[" 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:16<00:10,  1.37s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7246996313454552 ACC : 0.6686567164179105\n","\n","Training steps: 0 Loss: 0.4806648790836334\n","Training steps: 50 Loss: 0.5709667205810547\n","TRAIN AUC : 0.7800140754008222 ACC : 0.7125793206420306\n"],"name":"stdout"},{"output_type":"stream","text":[" 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:17<00:09,  1.36s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7243671281543171 ACC : 0.6716417910447762\n","\n","Training steps: 0 Loss: 0.6154234409332275\n","Training steps: 50 Loss: 0.5091397762298584\n","TRAIN AUC : 0.7803962496119634 ACC : 0.7129525942515864\n"],"name":"stdout"},{"output_type":"stream","text":[" 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:19<00:08,  1.37s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7249406403699042 ACC : 0.6708955223880597\n","\n","Training steps: 0 Loss: 0.5425425171852112\n","Training steps: 50 Loss: 0.6158835291862488\n","TRAIN AUC : 0.7815982559009486 ACC : 0.70996640537514\n"],"name":"stdout"},{"output_type":"stream","text":[" 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:20<00:06,  1.36s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7241640557355685 ACC : 0.676865671641791\n","\n","Training steps: 0 Loss: 0.563831090927124\n","Training steps: 50 Loss: 0.5104947686195374\n","TRAIN AUC : 0.7814802397228915 ACC : 0.713699141470698\n"],"name":"stdout"},{"output_type":"stream","text":[" 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:21<00:07,  1.45s/it]\n","/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","  0%|          | 0/20 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7249696507154397 ACC : 0.6671641791044776\n","\n","EarlyStopping counter: 5 out of 5\n","VALID AUC : 0.7254851422399557 ACC : 0.6708955223880597\n","\n","AUC : 0.7254851422399557, ACC : 0.6708955223880597\n","Calculating train oof 3\n","Training steps: 0 Loss: 0.6930814981460571\n","Training steps: 50 Loss: 0.6833211183547974\n","TRAIN AUC : 0.698597847764574 ACC : 0.6358715938783128\n"],"name":"stdout"},{"output_type":"stream","text":["  5%|â–Œ         | 1/20 [00:01<00:25,  1.35s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.749839327317034 ACC : 0.6970149253731344\n","\n","Training steps: 0 Loss: 0.6399450302124023\n","Training steps: 50 Loss: 0.5732077956199646\n","TRAIN AUC : 0.7389966489267856 ACC : 0.6821575214632325\n"],"name":"stdout"},{"output_type":"stream","text":[" 10%|â–ˆ         | 2/20 [00:02<00:24,  1.37s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7511894241669569 ACC : 0.6962686567164179\n","\n","Training steps: 0 Loss: 0.6014322638511658\n","Training steps: 50 Loss: 0.5520884990692139\n","TRAIN AUC : 0.747722657654539 ACC : 0.692795819335573\n"],"name":"stdout"},{"output_type":"stream","text":[" 15%|â–ˆâ–Œ        | 3/20 [00:04<00:23,  1.36s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.751776325772791 ACC : 0.7037313432835821\n","\n","Training steps: 0 Loss: 0.6003940105438232\n","Training steps: 50 Loss: 0.5356258749961853\n","TRAIN AUC : 0.7532300560336067 ACC : 0.6892497200447928\n"],"name":"stdout"},{"output_type":"stream","text":[" 20%|â–ˆâ–ˆ        | 4/20 [00:05<00:21,  1.37s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7529523605495005 ACC : 0.7007462686567164\n","\n","Training steps: 0 Loss: 0.5801949501037598\n","Training steps: 50 Loss: 0.6215693950653076\n","TRAIN AUC : 0.7567816381064258 ACC : 0.6974617394550205\n"],"name":"stdout"},{"output_type":"stream","text":[" 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:06<00:20,  1.36s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7523431432932544 ACC : 0.7022388059701492\n","\n","Training steps: 0 Loss: 0.5838621258735657\n","Training steps: 50 Loss: 0.5579959154129028\n","TRAIN AUC : 0.7603974276800212 ACC : 0.7006345651362449\n"],"name":"stdout"},{"output_type":"stream","text":[" 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:08<00:18,  1.35s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7527537512608342 ACC : 0.6925373134328359\n","\n","Training steps: 0 Loss: 0.5740272402763367\n","Training steps: 50 Loss: 0.52974933385849\n","TRAIN AUC : 0.7631212215281609 ACC : 0.7030608435983576\n"],"name":"stdout"},{"output_type":"stream","text":[" 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:09<00:17,  1.37s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7527827616063698 ACC : 0.7022388059701492\n","\n","Training steps: 0 Loss: 0.5927715301513672\n","Training steps: 50 Loss: 0.632649302482605\n","TRAIN AUC : 0.7652418836135758 ACC : 0.7038073908174692\n"],"name":"stdout"},{"output_type":"stream","text":[" 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:11<00:16,  1.41s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7518298833337796 ACC : 0.6917910447761194\n","\n","Training steps: 0 Loss: 0.4826279878616333\n","Training steps: 50 Loss: 0.531161367893219\n","TRAIN AUC : 0.7676616689036933 ACC : 0.7088465845464725\n"],"name":"stdout"},{"output_type":"stream","text":[" 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:12<00:18,  1.55s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7511403297360505 ACC : 0.685820895522388\n","\n","EarlyStopping counter: 5 out of 5\n","VALID AUC : 0.7529523605495005 ACC : 0.7007462686567164\n","\n","AUC : 0.7529523605495005, ACC : 0.7007462686567164\n","Calculating train oof 4\n"],"name":"stdout"},{"output_type":"stream","text":["\n","/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","  0%|          | 0/20 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Training steps: 0 Loss: 0.6969872713088989\n","Training steps: 50 Loss: 0.6563462018966675\n","TRAIN AUC : 0.7108980050966477 ACC : 0.6525471169994402\n"],"name":"stdout"},{"output_type":"stream","text":["  5%|â–Œ         | 1/20 [00:01<00:25,  1.33s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.729320232981239 ACC : 0.6721433905899925\n","\n","Training steps: 0 Loss: 0.6303619146347046\n","Training steps: 50 Loss: 0.5908609628677368\n","TRAIN AUC : 0.7434810125875813 ACC : 0.6913603284194813\n"],"name":"stdout"},{"output_type":"stream","text":[" 10%|â–ˆ         | 2/20 [00:02<00:24,  1.34s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7326996231711732 ACC : 0.6676624346527259\n","\n","Training steps: 0 Loss: 0.6156455278396606\n","Training steps: 50 Loss: 0.6292706727981567\n","TRAIN AUC : 0.749588325149601 ACC : 0.6993842134726628\n"],"name":"stdout"},{"output_type":"stream","text":[" 15%|â–ˆâ–Œ        | 3/20 [00:04<00:22,  1.34s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7355448372662701 ACC : 0.6721433905899925\n","\n","Training steps: 0 Loss: 0.5590441226959229\n","Training steps: 50 Loss: 0.6216742992401123\n","TRAIN AUC : 0.7538558327370872 ACC : 0.6990110095167009\n"],"name":"stdout"},{"output_type":"stream","text":[" 20%|â–ˆâ–ˆ        | 4/20 [00:05<00:22,  1.38s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.737033378183265 ACC : 0.6788648244958925\n","\n","Training steps: 0 Loss: 0.5951887369155884\n","Training steps: 50 Loss: 0.5624350309371948\n","TRAIN AUC : 0.7572817823309516 ACC : 0.704235864900168\n"],"name":"stdout"},{"output_type":"stream","text":[" 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:06<00:20,  1.37s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7389957489417054 ACC : 0.6751306945481703\n","\n","Training steps: 0 Loss: 0.5874776840209961\n","Training steps: 50 Loss: 0.543150007724762\n","TRAIN AUC : 0.7616129840615349 ACC : 0.7057286807240156\n"],"name":"stdout"},{"output_type":"stream","text":[" 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:08<00:19,  1.38s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.740283135680728 ACC : 0.6736370425690814\n","\n","Training steps: 0 Loss: 0.5348063707351685\n","Training steps: 50 Loss: 0.6366959810256958\n","TRAIN AUC : 0.7626392062356356 ACC : 0.7062884866579586\n"],"name":"stdout"},{"output_type":"stream","text":[" 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:09<00:17,  1.37s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7413626631025125 ACC : 0.6766243465272591\n","\n","Training steps: 0 Loss: 0.5815878510475159\n","Training steps: 50 Loss: 0.564761221408844\n","TRAIN AUC : 0.7641477737606361 ACC : 0.7066616906139205\n"],"name":"stdout"},{"output_type":"stream","text":[" 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:10<00:16,  1.36s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.741742620994238 ACC : 0.678117998506348\n","\n","Training steps: 0 Loss: 0.5808400511741638\n","Training steps: 50 Loss: 0.6267675757408142\n","TRAIN AUC : 0.7685234846514556 ACC : 0.7061018846799776\n"],"name":"stdout"},{"output_type":"stream","text":[" 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:12<00:15,  1.37s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7423885494101712 ACC : 0.6825989544436146\n","\n","Training steps: 0 Loss: 0.6112120151519775\n","Training steps: 50 Loss: 0.554948091506958\n","TRAIN AUC : 0.7685103690995364 ACC : 0.7075947005038253\n"],"name":"stdout"},{"output_type":"stream","text":[" 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:13<00:14,  1.40s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7428690843908827 ACC : 0.6803584764749814\n","\n","Training steps: 0 Loss: 0.5343686938285828\n","Training steps: 50 Loss: 0.5656194686889648\n","TRAIN AUC : 0.7709673026500112 ACC : 0.7122597499533495\n"],"name":"stdout"},{"output_type":"stream","text":[" 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:15<00:12,  1.43s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7424667760349382 ACC : 0.6840926064227035\n","\n","Training steps: 0 Loss: 0.7146446108818054\n","Training steps: 50 Loss: 0.548346757888794\n","TRAIN AUC : 0.770174788448938 ACC : 0.7066616906139205\n"],"name":"stdout"},{"output_type":"stream","text":[" 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:16<00:11,  1.44s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7439508468590893 ACC : 0.6758775205377147\n","\n","Training steps: 0 Loss: 0.6551114320755005\n","Training steps: 50 Loss: 0.5302891135215759\n","TRAIN AUC : 0.7721141460436239 ACC : 0.7133793618212353\n"],"name":"stdout"},{"output_type":"stream","text":[" 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:18<00:10,  1.45s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7435440684103009 ACC : 0.6915608663181478\n","\n","Training steps: 0 Loss: 0.4894910454750061\n","Training steps: 50 Loss: 0.46966975927352905\n","TRAIN AUC : 0.7748922013253963 ACC : 0.7118865459973875\n"],"name":"stdout"},{"output_type":"stream","text":[" 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:19<00:08,  1.44s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7441318856192642 ACC : 0.6758775205377147\n","\n","Training steps: 0 Loss: 0.5919384956359863\n","Training steps: 50 Loss: 0.5283548831939697\n","TRAIN AUC : 0.7757269922523365 ACC : 0.7113267400634447\n"],"name":"stdout"},{"output_type":"stream","text":[" 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:21<00:07,  1.46s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7438636800486347 ACC : 0.6908140403286034\n","\n","Training steps: 0 Loss: 0.6434837579727173\n","Training steps: 50 Loss: 0.5619356036186218\n","TRAIN AUC : 0.7754503099177014 ACC : 0.7137525657771973\n"],"name":"stdout"},{"output_type":"stream","text":[" 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:22<00:05,  1.46s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7440648342266069 ACC : 0.6893203883495146\n","\n","Training steps: 0 Loss: 0.5449098348617554\n","Training steps: 50 Loss: 0.5601534843444824\n","TRAIN AUC : 0.7754868660304972 ACC : 0.7144989736891211\n"],"name":"stdout"},{"output_type":"stream","text":[" 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:24<00:04,  1.45s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7436312352207555 ACC : 0.6908140403286034\n","\n","Training steps: 0 Loss: 0.4987950921058655\n","Training steps: 50 Loss: 0.5911628007888794\n","TRAIN AUC : 0.7761430622078999 ACC : 0.7124463519313304\n"],"name":"stdout"},{"output_type":"stream","text":[" 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:25<00:02,  1.43s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7447129976889619 ACC : 0.6945481702763256\n","\n","Training steps: 0 Loss: 0.553540050983429\n","Training steps: 50 Loss: 0.477896511554718\n","TRAIN AUC : 0.7749307108182653 ACC : 0.7118865459973875\n"],"name":"stdout"},{"output_type":"stream","text":[" 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:26<00:01,  1.42s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7450661350236245 ACC : 0.6945481702763256\n","\n","Training steps: 0 Loss: 0.49705782532691956\n","Training steps: 50 Loss: 0.6964040398597717\n","TRAIN AUC : 0.7768118855922034 ACC : 0.7131927598432544\n"],"name":"stdout"},{"output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:28<00:00,  1.41s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7439374365805578 ACC : 0.6825989544436146\n","\n","VALID AUC : 0.7450661350236245 ACC : 0.6945481702763256\n","\n","AUC : 0.7450661350236245, ACC : 0.6945481702763256\n","Calculating train oof 5\n"],"name":"stdout"},{"output_type":"stream","text":["\n","/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","  0%|          | 0/20 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Training steps: 0 Loss: 0.6948795914649963\n","Training steps: 50 Loss: 0.6592923402786255\n","TRAIN AUC : 0.7078715914912996 ACC : 0.6415376002985632\n"],"name":"stdout"},{"output_type":"stream","text":["  5%|â–Œ         | 1/20 [00:01<00:26,  1.41s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7513577907013129 ACC : 0.6908140403286034\n","\n","Training steps: 0 Loss: 0.5973723530769348\n","Training steps: 50 Loss: 0.6874881982803345\n","TRAIN AUC : 0.7384327808430342 ACC : 0.6797910057846613\n"],"name":"stdout"},{"output_type":"stream","text":[" 10%|â–ˆ         | 2/20 [00:02<00:25,  1.43s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7564291110326362 ACC : 0.6952949962658701\n","\n","Training steps: 0 Loss: 0.5825499892234802\n","Training steps: 50 Loss: 0.5232782363891602\n","TRAIN AUC : 0.7470325366147142 ACC : 0.6900541145736144\n"],"name":"stdout"},{"output_type":"stream","text":[" 15%|â–ˆâ–Œ        | 3/20 [00:04<00:23,  1.40s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7603829081530024 ACC : 0.6982823002240478\n","\n","Training steps: 0 Loss: 0.5388591289520264\n","Training steps: 50 Loss: 0.5713480710983276\n","TRAIN AUC : 0.7524925129732343 ACC : 0.6935995521552528\n"],"name":"stdout"},{"output_type":"stream","text":[" 20%|â–ˆâ–ˆ        | 4/20 [00:05<00:22,  1.38s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7616401217653291 ACC : 0.700522778192681\n","\n","Training steps: 0 Loss: 0.6127632856369019\n","Training steps: 50 Loss: 0.6102468967437744\n","TRAIN AUC : 0.7573251752740034 ACC : 0.6975181936928532\n"],"name":"stdout"},{"output_type":"stream","text":[" 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:06<00:20,  1.36s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7642070725808975 ACC : 0.700522778192681\n","\n","Training steps: 0 Loss: 0.6541475057601929\n","Training steps: 50 Loss: 0.6329292058944702\n","TRAIN AUC : 0.7615306630441698 ACC : 0.7029296510543012\n"],"name":"stdout"},{"output_type":"stream","text":[" 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:08<00:18,  1.34s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.764113200631177 ACC : 0.7050037341299478\n","\n","Training steps: 0 Loss: 0.6095543503761292\n","Training steps: 50 Loss: 0.6181750297546387\n","TRAIN AUC : 0.7636682189526981 ACC : 0.7062884866579586\n"],"name":"stdout"},{"output_type":"stream","text":[" 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:09<00:18,  1.39s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7638695805711885 ACC : 0.7027632561613144\n","\n","Training steps: 0 Loss: 0.5597216486930847\n","Training steps: 50 Loss: 0.5610495805740356\n","TRAIN AUC : 0.7650117956250984 ACC : 0.7031162530322821\n"],"name":"stdout"},{"output_type":"stream","text":[" 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:11<00:17,  1.43s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7639545123352212 ACC : 0.700522778192681\n","\n","Training steps: 0 Loss: 0.6315510272979736\n","Training steps: 50 Loss: 0.5625433921813965\n","TRAIN AUC : 0.7684743710953328 ACC : 0.7081545064377682\n"],"name":"stdout"},{"output_type":"stream","text":[" 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:12<00:15,  1.42s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.762629129807026 ACC : 0.7012696041822255\n","\n","Training steps: 0 Loss: 0.6715253591537476\n","Training steps: 50 Loss: 0.5962334871292114\n","TRAIN AUC : 0.7694085053517032 ACC : 0.7087143123717111\n"],"name":"stdout"},{"output_type":"stream","text":[" 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:13<00:17,  1.55s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7637142448448654 ACC : 0.6982823002240478\n","\n","EarlyStopping counter: 5 out of 5\n","VALID AUC : 0.7642070725808975 ACC : 0.700522778192681\n","\n","AUC : 0.7642070725808975, ACC : 0.700522778192681\n","training oof stacking model [ 3 ]\n","Calculating train oof 1\n"],"name":"stdout"},{"output_type":"stream","text":["\n","/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","  0%|          | 0/20 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Training steps: 0 Loss: 0.6904752850532532\n","Training steps: 50 Loss: 0.5829167366027832\n","TRAIN AUC : 0.7124114634396908 ACC : 0.6763717805151176\n"],"name":"stdout"},{"output_type":"stream","text":["  5%|â–Œ         | 1/20 [00:02<00:42,  2.26s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7567683367699436 ACC : 0.6925373134328359\n","\n","Training steps: 0 Loss: 0.6019041538238525\n","Training steps: 50 Loss: 0.6896251440048218\n","TRAIN AUC : 0.7476551699879626 ACC : 0.6857036207540127\n"],"name":"stdout"},{"output_type":"stream","text":[" 10%|â–ˆ         | 2/20 [00:04<00:40,  2.27s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.759307857786823 ACC : 0.691044776119403\n","\n","Training steps: 0 Loss: 0.5983484387397766\n","Training steps: 50 Loss: 0.5683490037918091\n","TRAIN AUC : 0.7590690303215736 ACC : 0.6903695408734603\n"],"name":"stdout"},{"output_type":"stream","text":[" 15%|â–ˆâ–Œ        | 3/20 [00:06<00:38,  2.24s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7605352185594801 ACC : 0.6902985074626866\n","\n","Training steps: 0 Loss: 0.49675220251083374\n","Training steps: 50 Loss: 0.5790495276451111\n","TRAIN AUC : 0.7675701034243256 ACC : 0.7047405748413588\n"],"name":"stdout"},{"output_type":"stream","text":[" 20%|â–ˆâ–ˆ        | 4/20 [00:08<00:35,  2.25s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7593368681323587 ACC : 0.6940298507462687\n","\n","Training steps: 0 Loss: 0.5530460476875305\n","Training steps: 50 Loss: 0.5678777694702148\n","TRAIN AUC : 0.772881738716788 ACC : 0.7097797685703621\n"],"name":"stdout"},{"output_type":"stream","text":[" 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:11<00:33,  2.24s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7584040739451392 ACC : 0.6850746268656717\n","\n","Training steps: 0 Loss: 0.68317711353302\n","Training steps: 50 Loss: 0.5947957038879395\n","TRAIN AUC : 0.777810292518207 ACC : 0.7101530421799179\n"],"name":"stdout"},{"output_type":"stream","text":[" 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:13<00:30,  2.20s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7571053030911638 ACC : 0.6865671641791045\n","\n","Training steps: 0 Loss: 0.6430057287216187\n","Training steps: 50 Loss: 0.6025107502937317\n","TRAIN AUC : 0.7783943016122225 ACC : 0.7123926838372527\n"],"name":"stdout"},{"output_type":"stream","text":[" 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:15<00:29,  2.24s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.75842415803051 ACC : 0.6835820895522388\n","\n","Training steps: 0 Loss: 0.5641331672668457\n","Training steps: 50 Loss: 0.6404780149459839\n","TRAIN AUC : 0.7825317073388616 ACC : 0.7101530421799179\n"],"name":"stdout"},{"output_type":"stream","text":[" 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:17<00:33,  2.56s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7583505163841505 ACC : 0.685820895522388\n","\n","EarlyStopping counter: 5 out of 5\n"],"name":"stdout"},{"output_type":"stream","text":["\n","/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","  0%|          | 0/20 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7605352185594801 ACC : 0.6902985074626866\n","\n","AUC : 0.7605352185594801, ACC : 0.6902985074626866\n","Calculating train oof 2\n","Training steps: 0 Loss: 0.6940299272537231\n","Training steps: 50 Loss: 0.6473267078399658\n","TRAIN AUC : 0.7232475260570789 ACC : 0.6761851437103397\n"],"name":"stdout"},{"output_type":"stream","text":["  5%|â–Œ         | 1/20 [00:02<00:42,  2.25s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7188573940676075 ACC : 0.676865671641791\n","\n","Training steps: 0 Loss: 0.5707770586013794\n","Training steps: 50 Loss: 0.5861775875091553\n","TRAIN AUC : 0.7566090455527094 ACC : 0.7017543859649122\n"],"name":"stdout"},{"output_type":"stream","text":[" 10%|â–ˆ         | 2/20 [00:04<00:40,  2.25s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7217227235805015 ACC : 0.6701492537313433\n","\n","Training steps: 0 Loss: 0.5758934617042542\n","Training steps: 50 Loss: 0.5930904746055603\n","TRAIN AUC : 0.7654721931272293 ACC : 0.706047032474804\n"],"name":"stdout"},{"output_type":"stream","text":[" 15%|â–ˆâ–Œ        | 3/20 [00:06<00:38,  2.25s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7238538681948424 ACC : 0.6776119402985075\n","\n","Training steps: 0 Loss: 0.7286087274551392\n","Training steps: 50 Loss: 0.6150184869766235\n","TRAIN AUC : 0.775338582901375 ACC : 0.7122060470324748\n"],"name":"stdout"},{"output_type":"stream","text":[" 20%|â–ˆâ–ˆ        | 4/20 [00:08<00:35,  2.24s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7244697801462121 ACC : 0.6753731343283582\n","\n","Training steps: 0 Loss: 0.6063029170036316\n","Training steps: 50 Loss: 0.583661675453186\n","TRAIN AUC : 0.7818883063066281 ACC : 0.7168719671519224\n"],"name":"stdout"},{"output_type":"stream","text":[" 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:11<00:33,  2.25s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7230103366092708 ACC : 0.6694029850746268\n","\n","Training steps: 0 Loss: 0.5747852325439453\n","Training steps: 50 Loss: 0.5427356362342834\n","TRAIN AUC : 0.7847745730480361 ACC : 0.7183650615901456\n"],"name":"stdout"},{"output_type":"stream","text":[" 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:13<00:31,  2.26s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7241339296075123 ACC : 0.6664179104477612\n","\n","Training steps: 0 Loss: 0.6099811792373657\n","Training steps: 50 Loss: 0.609664797782898\n","TRAIN AUC : 0.7901523001918408 ACC : 0.72508398656215\n"],"name":"stdout"},{"output_type":"stream","text":[" 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:15<00:28,  2.22s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7247955886422266 ACC : 0.673134328358209\n","\n","Training steps: 0 Loss: 0.6210029721260071\n","Training steps: 50 Loss: 0.49923062324523926\n","TRAIN AUC : 0.7934368628103456 ACC : 0.7245240761478163\n"],"name":"stdout"},{"output_type":"stream","text":[" 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:17<00:26,  2.22s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7238114684590597 ACC : 0.6716417910447762\n","\n","Training steps: 0 Loss: 0.5845032334327698\n","Training steps: 50 Loss: 0.5165998935699463\n","TRAIN AUC : 0.7947461375000837 ACC : 0.7239641657334827\n"],"name":"stdout"},{"output_type":"stream","text":[" 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:20<00:24,  2.20s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7235816172598166 ACC : 0.673134328358209\n","\n","Training steps: 0 Loss: 0.4363022744655609\n","Training steps: 50 Loss: 0.6925041675567627\n","TRAIN AUC : 0.797673929744711 ACC : 0.7293766330720418\n"],"name":"stdout"},{"output_type":"stream","text":[" 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:22<00:22,  2.24s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7236574904712173 ACC : 0.6776119402985075\n","\n","Training steps: 0 Loss: 0.5400385856628418\n","Training steps: 50 Loss: 0.4908074736595154\n","TRAIN AUC : 0.7983845392804739 ACC : 0.7306830907054871\n"],"name":"stdout"},{"output_type":"stream","text":[" 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:24<00:20,  2.23s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7226220442921029 ACC : 0.6738805970149254\n","\n","Training steps: 0 Loss: 0.5053907632827759\n","Training steps: 50 Loss: 0.47530317306518555\n","TRAIN AUC : 0.7981614880060388 ACC : 0.7284434490481523\n"],"name":"stdout"},{"output_type":"stream","text":[" 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:26<00:21,  2.44s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7230259575645591 ACC : 0.673134328358209\n","\n","EarlyStopping counter: 5 out of 5\n"],"name":"stdout"},{"output_type":"stream","text":["\n","/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","  0%|          | 0/20 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7247955886422266 ACC : 0.673134328358209\n","\n","AUC : 0.7247955886422266, ACC : 0.673134328358209\n","Calculating train oof 3\n","Training steps: 0 Loss: 0.6947785019874573\n","Training steps: 50 Loss: 0.603216290473938\n","TRAIN AUC : 0.71820165398522 ACC : 0.6759985069055617\n"],"name":"stdout"},{"output_type":"stream","text":["  5%|â–Œ         | 1/20 [00:02<00:41,  2.19s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.750894857581519 ACC : 0.7007462686567164\n","\n","Training steps: 0 Loss: 0.5970847606658936\n","Training steps: 50 Loss: 0.6351062059402466\n","TRAIN AUC : 0.7475016303121935 ACC : 0.6899962672639044\n"],"name":"stdout"},{"output_type":"stream","text":[" 10%|â–ˆ         | 2/20 [00:04<00:39,  2.22s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7574913638432906 ACC : 0.7037313432835821\n","\n","Training steps: 0 Loss: 0.5552574396133423\n","Training steps: 50 Loss: 0.6383385062217712\n","TRAIN AUC : 0.7563790152021029 ACC : 0.6976483762597985\n"],"name":"stdout"},{"output_type":"stream","text":[" 15%|â–ˆâ–Œ        | 3/20 [00:06<00:38,  2.27s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.761325192584063 ACC : 0.7089552238805971\n","\n","Training steps: 0 Loss: 0.555010199546814\n","Training steps: 50 Loss: 0.576459527015686\n","TRAIN AUC : 0.7650539370922823 ACC : 0.7036207540126913\n"],"name":"stdout"},{"output_type":"stream","text":[" 20%|â–ˆâ–ˆ        | 4/20 [00:09<00:37,  2.37s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7647729605727089 ACC : 0.7044776119402985\n","\n","Training steps: 0 Loss: 0.5431627035140991\n","Training steps: 50 Loss: 0.6094051003456116\n","TRAIN AUC : 0.7720225446493377 ACC : 0.7101530421799179\n"],"name":"stdout"},{"output_type":"stream","text":[" 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:12<00:37,  2.47s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7653933356541609 ACC : 0.7052238805970149\n","\n","Training steps: 0 Loss: 0.5121634006500244\n","Training steps: 50 Loss: 0.6231368780136108\n","TRAIN AUC : 0.7756414050164483 ACC : 0.7135125046659201\n"],"name":"stdout"},{"output_type":"stream","text":[" 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:14<00:34,  2.47s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7653152308777192 ACC : 0.7082089552238806\n","\n","Training steps: 0 Loss: 0.5601663589477539\n","Training steps: 50 Loss: 0.46030867099761963\n","TRAIN AUC : 0.7792235554428978 ACC : 0.7146323254945876\n"],"name":"stdout"},{"output_type":"stream","text":[" 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:17<00:32,  2.52s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7638312401253247 ACC : 0.7022388059701492\n","\n","Training steps: 0 Loss: 0.6382269859313965\n","Training steps: 50 Loss: 0.6712929606437683\n","TRAIN AUC : 0.7809455029066457 ACC : 0.717431877566256\n"],"name":"stdout"},{"output_type":"stream","text":[" 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:19<00:30,  2.53s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7662569513251034 ACC : 0.7052238805970149\n","\n","Training steps: 0 Loss: 0.5823442935943604\n","Training steps: 50 Loss: 0.5513052344322205\n","TRAIN AUC : 0.7825125846701522 ACC : 0.7142590518850317\n"],"name":"stdout"},{"output_type":"stream","text":[" 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:22<00:27,  2.54s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7658619643128118 ACC : 0.7044776119402985\n","\n","Training steps: 0 Loss: 0.597847580909729\n","Training steps: 50 Loss: 0.5193931460380554\n","TRAIN AUC : 0.784487802808157 ACC : 0.7172452407614781\n"],"name":"stdout"},{"output_type":"stream","text":[" 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:24<00:24,  2.46s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7657860911014113 ACC : 0.7022388059701492\n","\n","Training steps: 0 Loss: 0.4382109045982361\n","Training steps: 50 Loss: 0.5222349762916565\n","TRAIN AUC : 0.7864261016332156 ACC : 0.7202314296379246\n"],"name":"stdout"},{"output_type":"stream","text":[" 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:27<00:22,  2.49s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7672946290692588 ACC : 0.7044776119402985\n","\n","Training steps: 0 Loss: 0.5500537753105164\n","Training steps: 50 Loss: 0.5842977166175842\n","TRAIN AUC : 0.7879450975619016 ACC : 0.7196715192235908\n"],"name":"stdout"},{"output_type":"stream","text":[" 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:29<00:20,  2.54s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7671161038659633 ACC : 0.7104477611940299\n","\n","Training steps: 0 Loss: 0.5074284076690674\n","Training steps: 50 Loss: 0.5652563571929932\n","TRAIN AUC : 0.7890675423825337 ACC : 0.7183650615901456\n"],"name":"stdout"},{"output_type":"stream","text":[" 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:32<00:17,  2.48s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7670357675244802 ACC : 0.7007462686567164\n","\n","Training steps: 0 Loss: 0.6681637763977051\n","Training steps: 50 Loss: 0.5892723798751831\n","TRAIN AUC : 0.7900938853242869 ACC : 0.7189249720044792\n"],"name":"stdout"},{"output_type":"stream","text":[" 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:34<00:14,  2.47s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7659847003900776 ACC : 0.6992537313432836\n","\n","Training steps: 0 Loss: 0.5612510442733765\n","Training steps: 50 Loss: 0.5845701694488525\n","TRAIN AUC : 0.7907244448563651 ACC : 0.7215378872713699\n"],"name":"stdout"},{"output_type":"stream","text":[" 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:37<00:12,  2.54s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7684282641101857 ACC : 0.7119402985074627\n","\n","Training steps: 0 Loss: 0.5217329859733582\n","Training steps: 50 Loss: 0.5420700907707214\n","TRAIN AUC : 0.7905614834277648 ACC : 0.7228443449048152\n"],"name":"stdout"},{"output_type":"stream","text":[" 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:39<00:10,  2.54s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7680645190084711 ACC : 0.7067164179104478\n","\n","Training steps: 0 Loss: 0.5981107950210571\n","Training steps: 50 Loss: 0.5550518035888672\n","TRAIN AUC : 0.7905279838621426 ACC : 0.7219111608809258\n"],"name":"stdout"},{"output_type":"stream","text":[" 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:42<00:07,  2.55s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7687362200858706 ACC : 0.7089552238805971\n","\n","Training steps: 0 Loss: 0.5080734491348267\n","Training steps: 50 Loss: 0.5582491159439087\n","TRAIN AUC : 0.7926630228444704 ACC : 0.7196715192235908\n"],"name":"stdout"},{"output_type":"stream","text":[" 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:45<00:05,  2.54s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7682028760410251 ACC : 0.7059701492537314\n","\n","Training steps: 0 Loss: 0.49313852190971375\n","Training steps: 50 Loss: 0.4808726906776428\n","TRAIN AUC : 0.7928839803960542 ACC : 0.7211646136618141\n"],"name":"stdout"},{"output_type":"stream","text":[" 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:47<00:02,  2.57s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7679663301466585 ACC : 0.7022388059701492\n","\n","Training steps: 0 Loss: 0.6344562768936157\n","Training steps: 50 Loss: 0.4729847311973572\n","TRAIN AUC : 0.7936475611199574 ACC : 0.7235908921239268\n"],"name":"stdout"},{"output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:50<00:00,  2.52s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7686670415695936 ACC : 0.7044776119402985\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","  0%|          | 0/20 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7687362200858706 ACC : 0.7089552238805971\n","\n","AUC : 0.7687362200858706, ACC : 0.7089552238805971\n","Calculating train oof 4\n","Training steps: 0 Loss: 0.6908524036407471\n","Training steps: 50 Loss: 0.6004118919372559\n","TRAIN AUC : 0.7208878698446115 ACC : 0.6685948871058033\n"],"name":"stdout"},{"output_type":"stream","text":["  5%|â–Œ         | 1/20 [00:02<00:50,  2.64s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7340652365349628 ACC : 0.6721433905899925\n","\n","Training steps: 0 Loss: 0.5546128153800964\n","Training steps: 50 Loss: 0.5598793029785156\n","TRAIN AUC : 0.7534512737712402 ACC : 0.6963985818249674\n"],"name":"stdout"},{"output_type":"stream","text":[" 10%|â–ˆ         | 2/20 [00:05<00:46,  2.60s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7389488129668453 ACC : 0.6825989544436146\n","\n","Training steps: 0 Loss: 0.6552712917327881\n","Training steps: 50 Loss: 0.6119520664215088\n","TRAIN AUC : 0.7648608272508799 ACC : 0.7031162530322821\n"],"name":"stdout"},{"output_type":"stream","text":[" 15%|â–ˆâ–Œ        | 3/20 [00:07<00:43,  2.58s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.740466409487325 ACC : 0.6870799103808812\n","\n","Training steps: 0 Loss: 0.5069973468780518\n","Training steps: 50 Loss: 0.6008214950561523\n","TRAIN AUC : 0.7716177084507686 ACC : 0.7059152827019967\n"],"name":"stdout"},{"output_type":"stream","text":[" 20%|â–ˆâ–ˆ        | 4/20 [00:10<00:40,  2.55s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.741295611709855 ACC : 0.6743838685586259\n","\n","Training steps: 0 Loss: 0.589529275894165\n","Training steps: 50 Loss: 0.624699592590332\n","TRAIN AUC : 0.7791553138077181 ACC : 0.7133793618212353\n"],"name":"stdout"},{"output_type":"stream","text":[" 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:12<00:38,  2.56s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.741483355609296 ACC : 0.6945481702763256\n","\n","Training steps: 0 Loss: 0.5291919112205505\n","Training steps: 50 Loss: 0.5874624252319336\n","TRAIN AUC : 0.7827806476961836 ACC : 0.7161783914909498\n"],"name":"stdout"},{"output_type":"stream","text":[" 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:15<00:36,  2.58s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.743360794603704 ACC : 0.6908140403286034\n","\n","Training steps: 0 Loss: 0.5507558584213257\n","Training steps: 50 Loss: 0.6540195941925049\n","TRAIN AUC : 0.7866525260552997 ACC : 0.7195372270946072\n"],"name":"stdout"},{"output_type":"stream","text":[" 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:18<00:33,  2.59s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7440894197372478 ACC : 0.6938013442867812\n","\n","Training steps: 0 Loss: 0.46170517802238464\n","Training steps: 50 Loss: 0.573901891708374\n","TRAIN AUC : 0.7893381446014713 ACC : 0.720656838962493\n"],"name":"stdout"},{"output_type":"stream","text":[" 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:20<00:31,  2.63s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.742893669901524 ACC : 0.6773711725168036\n","\n","Training steps: 0 Loss: 0.6001670360565186\n","Training steps: 50 Loss: 0.5396748781204224\n","TRAIN AUC : 0.7910540494685131 ACC : 0.7212166448964359\n"],"name":"stdout"},{"output_type":"stream","text":[" 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:23<00:29,  2.67s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7427416867448338 ACC : 0.6915608663181478\n","\n","Training steps: 0 Loss: 0.48285412788391113\n","Training steps: 50 Loss: 0.4854501783847809\n","TRAIN AUC : 0.793274833320869 ACC : 0.7227094607202836\n"],"name":"stdout"},{"output_type":"stream","text":[" 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:26<00:26,  2.65s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7426701652593324 ACC : 0.6908140403286034\n","\n","Training steps: 0 Loss: 0.5878739356994629\n","Training steps: 50 Loss: 0.5681548118591309\n","TRAIN AUC : 0.7943992128436415 ACC : 0.726068296323941\n"],"name":"stdout"},{"output_type":"stream","text":[" 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:28<00:23,  2.65s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7431439951007782 ACC : 0.6803584764749814\n","\n","Training steps: 0 Loss: 0.582108199596405\n","Training steps: 50 Loss: 0.5984166264533997\n","TRAIN AUC : 0.7954222956569105 ACC : 0.7240156745661503\n"],"name":"stdout"},{"output_type":"stream","text":[" 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:31<00:21,  2.63s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7449096817740906 ACC : 0.6885735623599701\n","\n","Training steps: 0 Loss: 0.5362534523010254\n","Training steps: 50 Loss: 0.5058220028877258\n","TRAIN AUC : 0.7972838668665441 ACC : 0.7275611121477887\n"],"name":"stdout"},{"output_type":"stream","text":[" 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:33<00:18,  2.61s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7445453692073184 ACC : 0.6863330843913368\n","\n","Training steps: 0 Loss: 0.5228153467178345\n","Training steps: 50 Loss: 0.6450129747390747\n","TRAIN AUC : 0.7955467538729946 ACC : 0.7268147042358649\n"],"name":"stdout"},{"output_type":"stream","text":[" 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:36<00:16,  2.67s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7452427036909557 ACC : 0.6811053024645257\n","\n","Training steps: 0 Loss: 0.5860037803649902\n","Training steps: 50 Loss: 0.594489336013794\n","TRAIN AUC : 0.7973979303100963 ACC : 0.7219630528083598\n"],"name":"stdout"},{"output_type":"stream","text":[" 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:39<00:13,  2.67s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7441475309442178 ACC : 0.6855862584017924\n","\n","Training steps: 0 Loss: 0.5754761099815369\n","Training steps: 50 Loss: 0.6140103936195374\n","TRAIN AUC : 0.7982703935670172 ACC : 0.7273745101698078\n"],"name":"stdout"},{"output_type":"stream","text":[" 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:41<00:10,  2.66s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7441520010370615 ACC : 0.6938013442867812\n","\n","Training steps: 0 Loss: 0.5330248475074768\n","Training steps: 50 Loss: 0.556136429309845\n","TRAIN AUC : 0.7993895408217367 ACC : 0.7288673259936556\n"],"name":"stdout"},{"output_type":"stream","text":[" 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:44<00:07,  2.65s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.742732746559146 ACC : 0.6803584764749814\n","\n","Training steps: 0 Loss: 0.5870082378387451\n","Training steps: 50 Loss: 0.5955429077148438\n","TRAIN AUC : 0.7987839929990856 ACC : 0.726441500279903\n"],"name":"stdout"},{"output_type":"stream","text":[" 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:47<00:05,  2.62s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7431104694044496 ACC : 0.6833457804331591\n","\n","Training steps: 0 Loss: 0.4964333176612854\n","Training steps: 50 Loss: 0.5392411351203918\n","TRAIN AUC : 0.799819982073552 ACC : 0.7275611121477887\n"],"name":"stdout"},{"output_type":"stream","text":[" 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:49<00:05,  2.76s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7432088114470138 ACC : 0.672890216579537\n","\n","EarlyStopping counter: 5 out of 5\n"],"name":"stdout"},{"output_type":"stream","text":["\n","/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","  0%|          | 0/20 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7452427036909557 ACC : 0.6811053024645257\n","\n","AUC : 0.7452427036909557, ACC : 0.6811053024645257\n","Calculating train oof 5\n","Training steps: 0 Loss: 0.6966573596000671\n","Training steps: 50 Loss: 0.6070038080215454\n","TRAIN AUC : 0.7134385851723941 ACC : 0.6738197424892703\n"],"name":"stdout"},{"output_type":"stream","text":["  5%|â–Œ         | 1/20 [00:02<00:49,  2.61s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7548981042336249 ACC : 0.6990291262135923\n","\n","Training steps: 0 Loss: 0.62331223487854\n","Training steps: 50 Loss: 0.5899903774261475\n","TRAIN AUC : 0.7430149919130066 ACC : 0.6855756671020713\n"],"name":"stdout"},{"output_type":"stream","text":[" 10%|â–ˆ         | 2/20 [00:05<00:46,  2.58s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7596252274159734 ACC : 0.700522778192681\n","\n","Training steps: 0 Loss: 0.6825073957443237\n","Training steps: 50 Loss: 0.5890508890151978\n","TRAIN AUC : 0.7519284047135618 ACC : 0.6941593580891957\n"],"name":"stdout"},{"output_type":"stream","text":[" 15%|â–ˆâ–Œ        | 3/20 [00:07<00:42,  2.48s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7629666218167351 ACC : 0.700522778192681\n","\n","Training steps: 0 Loss: 0.5520629286766052\n","Training steps: 50 Loss: 0.551970362663269\n","TRAIN AUC : 0.7588599041392682 ACC : 0.6943459600671767\n"],"name":"stdout"},{"output_type":"stream","text":[" 20%|â–ˆâ–ˆ        | 4/20 [00:09<00:38,  2.41s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7645266842192312 ACC : 0.7035100821508589\n","\n","Training steps: 0 Loss: 0.5628805756568909\n","Training steps: 50 Loss: 0.5637942552566528\n","TRAIN AUC : 0.7653789613152611 ACC : 0.704049262922187\n"],"name":"stdout"},{"output_type":"stream","text":[" 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:11<00:35,  2.36s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7679552454304475 ACC : 0.7102315160567588\n","\n","Training steps: 0 Loss: 0.5600907206535339\n","Training steps: 50 Loss: 0.5372666120529175\n","TRAIN AUC : 0.7703452906238872 ACC : 0.7090875163276731\n"],"name":"stdout"},{"output_type":"stream","text":[" 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:14<00:32,  2.31s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7683352033221729 ACC : 0.7087378640776699\n","\n","Training steps: 0 Loss: 0.5481971502304077\n","Training steps: 50 Loss: 0.5293270349502563\n","TRAIN AUC : 0.7750946552172548 ACC : 0.7049822728120918\n"],"name":"stdout"},{"output_type":"stream","text":[" 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:16<00:30,  2.32s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.76716403899709 ACC : 0.7064973861090366\n","\n","Training steps: 0 Loss: 0.5863957405090332\n","Training steps: 50 Loss: 0.47688427567481995\n","TRAIN AUC : 0.7786454816086477 ACC : 0.7133793618212353\n"],"name":"stdout"},{"output_type":"stream","text":[" 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:18<00:27,  2.30s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.765885592443755 ACC : 0.7012696041822255\n","\n","Training steps: 0 Loss: 0.5700546503067017\n","Training steps: 50 Loss: 0.5265052318572998\n","TRAIN AUC : 0.7793496751249884 ACC : 0.7126329539093115\n"],"name":"stdout"},{"output_type":"stream","text":[" 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:20<00:25,  2.29s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7668366046962795 ACC : 0.7087378640776699\n","\n","Training steps: 0 Loss: 0.5642219185829163\n","Training steps: 50 Loss: 0.5839836597442627\n","TRAIN AUC : 0.7836105551729411 ACC : 0.7178578092927785\n"],"name":"stdout"},{"output_type":"stream","text":[" 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:23<00:22,  2.28s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7689766616452625 ACC : 0.7094846900672144\n","\n","Training steps: 0 Loss: 0.6540666818618774\n","Training steps: 50 Loss: 0.5243140459060669\n","TRAIN AUC : 0.7842620074273092 ACC : 0.7193506251166263\n"],"name":"stdout"},{"output_type":"stream","text":[" 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:25<00:20,  2.31s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7662700204283243 ACC : 0.707244212098581\n","\n","Training steps: 0 Loss: 0.5624690055847168\n","Training steps: 50 Loss: 0.5665079355239868\n","TRAIN AUC : 0.7814342107172476 ACC : 0.7172980033588356\n"],"name":"stdout"},{"output_type":"stream","text":[" 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:27<00:18,  2.30s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7697209321037597 ACC : 0.7094846900672144\n","\n","Training steps: 0 Loss: 0.6365030407905579\n","Training steps: 50 Loss: 0.622056245803833\n","TRAIN AUC : 0.7852070248012296 ACC : 0.7219630528083598\n"],"name":"stdout"},{"output_type":"stream","text":[" 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:30<00:16,  2.30s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7684626009682222 ACC : 0.707244212098581\n","\n","Training steps: 0 Loss: 0.5523163080215454\n","Training steps: 50 Loss: 0.5637399554252625\n","TRAIN AUC : 0.7870956642775898 ACC : 0.7236424706101885\n"],"name":"stdout"},{"output_type":"stream","text":[" 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:32<00:13,  2.29s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7692828630050647 ACC : 0.6908140403286034\n","\n","Training steps: 0 Loss: 0.5945239663124084\n","Training steps: 50 Loss: 0.6133461594581604\n","TRAIN AUC : 0.7885078883068437 ACC : 0.726068296323941\n"],"name":"stdout"},{"output_type":"stream","text":[" 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:34<00:11,  2.30s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7689263731007694 ACC : 0.7117251680358476\n","\n","Training steps: 0 Loss: 0.594882607460022\n","Training steps: 50 Loss: 0.5840599536895752\n","TRAIN AUC : 0.7881650003404461 ACC : 0.7266281022578839\n"],"name":"stdout"},{"output_type":"stream","text":[" 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:36<00:09,  2.29s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7683396734150169 ACC : 0.70201643017177\n","\n","Training steps: 0 Loss: 0.505856454372406\n","Training steps: 50 Loss: 0.46768856048583984\n","TRAIN AUC : 0.7889136332534494 ACC : 0.7298003358835604\n"],"name":"stdout"},{"output_type":"stream","text":[" 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:39<00:09,  2.47s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7694884872758807 ACC : 0.7094846900672144\n","\n","EarlyStopping counter: 5 out of 5\n"],"name":"stdout"},{"output_type":"stream","text":["\n","/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7697209321037597 ACC : 0.7094846900672144\n","\n","AUC : 0.7697209321037597, ACC : 0.7094846900672144\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cGr_nm6iWXIA","outputId":"e32cec31-2dfb-41c3-a045-3e4b7d80ecca"},"source":["test_data[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([804, 804, 804, ..., 914, 914, 914]),\n"," array([4235, 4236, 4237, ..., 4963, 4964, 4965]),\n"," array([912, 912, 912, ..., 912, 912, 912]),\n"," array([ 1,  1,  0, ...,  1,  0, -1]))"]},"metadata":{"tags":[]},"execution_count":102}]},{"cell_type":"code","metadata":{"tags":[],"id":"DlVFGyl4WXIA","outputId":"fe03e625-9d76-4a77-efc5-064bf63d958d"},"source":["# Test\n","stacking = Stacking(Trainer())\n","test_predict, S_test = stacking.test(meta_model, models_list, test_data)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["test average stacking model [ 1 ]\n","Calculating test avg 1\n","Calculating test avg 2\n"],"name":"stdout"},{"output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n"],"name":"stderr"},{"output_type":"stream","text":["Calculating test avg 3\n","Calculating test avg 4\n","Calculating test avg 5\n","test average stacking model [ 2 ]\n","Calculating test avg 1\n","Calculating test avg 2\n","Calculating test avg 3\n","Calculating test avg 4\n","Calculating test avg 5\n","test average stacking model [ 3 ]\n","Calculating test avg 1\n","Calculating test avg 2\n","Calculating test avg 3\n","Calculating test avg 4\n","Calculating test avg 5\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cgyWNjvPWXIA"},"source":["### output.csv ìƒì„±"]},{"cell_type":"code","metadata":{"id":"_1bVNYF3WXIA","outputId":"11df81bc-6af7-40b3-d083-e9000b878921"},"source":["write_path = os.path.join(args.output_dir, \"output.csv\")\n","if not os.path.exists(args.output_dir):\n","    os.makedirs(args.output_dir)    \n","\n","with open(write_path, 'w', encoding='utf8') as w:\n","    print(\"writing prediction : {}\".format(write_path))\n","    w.write(\"id,prediction\\n\")\n","    for id, p in enumerate(test_predict):\n","        w.write('{},{}\\n'.format(id,p))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["writing prediction : output/output.csv\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QB_9F3EQWXIA"},"source":["## `Pseudo Labeling`\n","\n","> ì›í•˜ëŠ” ì‹¤í—˜ ì„¸íŒ…ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ pseudo labelingì„ ì§„í–‰í•œë‹¤. ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ê¸°ëŠ¥ì€ ì—†ìœ¼ë©° ê·¸ë ‡ê¸°ì— ì‹¤í—˜ ì„¸íŒ…ê°’(args)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ëª¨ë¸ì„ ì²˜ìŒë¶€í„° í›ˆë ¨í•˜ì—¬ ì§„í–‰í•œë‹¤. PseudoLabel í´ë˜ìŠ¤ì™€ Trainer í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ì§„í–‰í•  ê²ƒì´ë‹¤!"]},{"cell_type":"markdown","metadata":{"id":"7Y6-MQ1_WXIB"},"source":["### ì½”ë“œ\n","- Trainer\n","- PseudoLabel"]},{"cell_type":"markdown","metadata":{"id":"IrN7UpnVWXIB"},"source":["#### ğŸ’¯ Trainer\n","- ëª¨ë¸ í›ˆë ¨ ë° í›ˆë ¨ëœ ëª¨ë¸ return (ë² ì´ìŠ¤ë¼ì¸ `run`í•¨ìˆ˜ ê¸°ëŠ¥)\n","- ë°ì´í„° ì˜ˆì¸¡ê°’ì¸ predict ê°€ì ¸ì˜¤ê¸°\n","- ë°ì´í„° ë¼ë²¨ì¸ yê°’ ê°€ì ¸ì˜¤ê¸°"]},{"cell_type":"code","metadata":{"tags":[],"id":"XNciEGvHWXIB"},"source":["from tqdm import tqdm\n","\n","class Trainer:\n","    def __init__(self):\n","        pass\n","\n","    def train(self, args, train_data, valid_data):\n","        \"\"\"í›ˆë ¨ì„ ë§ˆì¹œ ëª¨ë¸ì„ ë°˜í™˜í•œë‹¤\"\"\"\n","\n","        # args update\n","        self.args = args\n","\n","        train_loader, valid_loader = get_loaders(args, train_data, valid_data)\n","        \n","        # only when using warmup scheduler\n","        args.total_steps = int(len(train_loader.dataset) / args.batch_size) * (args.n_epochs)\n","        args.warmup_steps = args.total_steps // 10\n","            \n","        model = get_model(args)\n","        optimizer = get_optimizer(model, args)\n","        scheduler = get_scheduler(optimizer, args)\n","\n","        best_auc = -1\n","        best_model = -1\n","        early_stopping_counter = 0\n","        for epoch in tqdm(range(args.n_epochs)):\n","\n","            ### TRAIN\n","            train_auc, train_acc, loss_avg = train(train_loader, model, optimizer, args)\n","            \n","            ### VALID\n","            auc, acc, preds, targets = validate(valid_loader, model, args)\n","\n","            ### model save or early stopping\n","            if auc > best_auc:\n","                best_auc = auc\n","                best_model = copy.deepcopy(model)\n","                early_stopping_counter = 0\n","            else:\n","                early_stopping_counter += 1\n","                if early_stopping_counter >= args.patience:\n","                    print(f'EarlyStopping counter: {early_stopping_counter} out of {args.patience}')\n","                    break\n","\n","            # scheduler\n","            if args.scheduler == 'plateau':\n","                scheduler.step(best_auc)\n","            else:\n","                scheduler.step()\n","\n","        return best_model\n","\n","    def evaluate(self, args, model, valid_data):\n","        \"\"\"í›ˆë ¨ëœ ëª¨ë¸ê³¼ validation ë°ì´í„°ì…‹ì„ ì œê³µí•˜ë©´ predict ë°˜í™˜\"\"\"\n","        pin_memory = False\n","\n","        valset = DKTDataset(valid_data, args)\n","        valid_loader = torch.utils.data.DataLoader(valset, shuffle=False,\n","                                                   batch_size=args.batch_size,\n","                                                   pin_memory=pin_memory,\n","                                                   collate_fn=collate)\n","\n","        auc, acc, preds, _ = validate(valid_loader, model, args)\n","        print(f\"AUC : {auc}, ACC : {acc}\")\n","\n","        return preds\n","\n","    def test(self, args, model, test_data):\n","        model.eval()\n","        _, test_loader = get_loaders(args, None, test_data)\n","\n","        total_preds = []\n","        for step, batch in enumerate(test_loader):\n","            input = process_batch(batch, args)\n","\n","            preds = model(input)\n","\n","            # predictions\n","            preds = preds[:,-1]\n","\n","            if args.device == 'cuda':\n","                preds = preds.to('cpu').detach().numpy()\n","            else: # cpu\n","                preds = preds.detach().numpy()\n","                \n","            total_preds.append(preds)\n","\n","        total_preds = np.concatenate(total_preds)\n","            \n","        return total_preds\n","\n","    def get_target(self, datas):\n","        targets = []\n","        for data in datas:\n","            targets.append(data[-1][-1])\n","\n","        return np.array(targets)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"14MBd2NnWXIB"},"source":["#### ğŸ’¯ PseudoLabel\n","> pseudo labelingì„ í¸ë¦¬í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ customí•˜ê²Œ êµ¬ì¶•ëœ í´ë˜ìŠ¤ë‹¤.\n","\n","- pseudo labeling í›ˆë ¨ ê³¼ì • ìë™í™”\n","- model, predictê°’ ì €ì¥\n","- test set ì˜ˆì¸¡ í›„ train set ì—…ë°ì´íŠ¸\n","- pseudo labeling ì§„í–‰ì— ë”°ë¥¸ validation ì„±ëŠ¥ ë³€í™” ì‹œê°í™”"]},{"cell_type":"code","metadata":{"tags":[],"id":"TnBBVDJXWXIB"},"source":["class PseudoLabel:\n","    def __init__(self, trainer):\n","        self.trainer = trainer\n","        \n","        # ê²°ê³¼ ì €ì¥ìš©\n","        self.models =[]\n","        self.preds =[]\n","        self.valid_aucs =[]\n","        self.valid_accs =[]\n","\n","    def visualize(self):\n","        aucs = self.valid_aucs\n","        accs = self.valid_accs\n","\n","        N = len(aucs)\n","        auc_min = min(aucs)\n","        auc_max = max(aucs)\n","        acc_min = min(accs)\n","        acc_max = max(accs)\n","\n","        experiment = ['base'] + [f'pseudo {i + 1}' for i in range(N - 1)]\n","        df = pd.DataFrame({'experiment': experiment, 'auc': aucs, 'acc': accs})\n","\n","        import matplotlib.pyplot as plt\n","\n","        fig, ax1 = plt.subplots(figsize=(5 + N, 7))\n","\n","        ax1.set_title('AUC of Pseudo Label Training Process', fontsize=16)\n","\n","        # Time\n","        plt.bar(df['experiment'],\n","                df['auc'],\n","                color='red',\n","                width=-0.3, align='edge',\n","                label='AUC')\n","        plt.ylabel('AUC (Area Under the ROC Curve)')\n","        ax1.set_ylim(auc_min - 0.002, auc_max + 0.002)\n","        ax1.axhline(y=aucs[0], color='r', linewidth=1)\n","        ax1.legend(loc=2)\n","\n","        # AUC\n","        ax2 = ax1.twinx()\n","        plt.bar(df['experiment'],\n","                df['acc'],\n","                color='blue',\n","                width=0.3, align='edge',\n","                label='ACC')\n","        plt.ylabel('ACC (Accuracy)')\n","\n","        ax2.grid(False)\n","        ax2.set_ylim(acc_min - 0.002, acc_max + 0.002)\n","        ax2.axhline(y=accs[0], color='b', linewidth=1)\n","        ax2.legend(loc=1)\n","\n","        plt.show()\n","\n","    def train(self, args, train_data, valid_data):\n","        model = self.trainer.train(args, train_data, valid_data)\n","\n","        # model ì €ì¥\n","        self.models.append(model)\n","        \n","        return model\n","\n","    def validate(self, args, model, valid_data):\n","        valid_target = self.trainer.get_target(valid_data)\n","        valid_predict = self.trainer.evaluate(args, model, valid_data)\n","\n","        # Metric\n","        valid_auc, valid_acc = get_metric(valid_target, valid_predict)\n","\n","        # auc / acc ì €ì¥\n","        self.valid_aucs.append(valid_auc)\n","        self.valid_accs.append(valid_acc)\n","\n","        print(f'Valid AUC : {valid_auc} Valid ACC : {valid_acc}')\n","\n","    def test(self, args, model, test_data):\n","        test_predict = self.trainer.test(args, model, test_data)\n","        self.preds.append(test_predict)\n","        pseudo_labels = np.where(test_predict >= 0.5, 1, 0)\n","        \n","        return pseudo_labels\n","\n","    def update_train_data(self, pseudo_labels, train_data, test_data):\n","        # pseudo ë¼ë²¨ì´ ë‹´ê¸¸ test ë°ì´í„° ë³µì‚¬ë³¸\n","        pseudo_test_data = copy.deepcopy(test_data)\n","\n","        # pseudo label í…ŒìŠ¤íŠ¸ ë°ì´í„° update\n","        for test_data, pseudo_label in zip(pseudo_test_data, pseudo_labels):\n","            test_data[-1][-1] = pseudo_label\n","\n","        # train data ì—…ë°ì´íŠ¸\n","        pseudo_train_data = np.concatenate((train_data, pseudo_test_data))\n","\n","        return pseudo_train_data\n","\n","    def run(self, N, args, train_data, valid_data, test_data):\n","        \"\"\"\n","        Nì€ ë‘ë²ˆì§¸ ê³¼ì •ì„ ëª‡ë²ˆ ë°˜ë³µí• ì§€ ë‚˜íƒ€ë‚¸ë‹¤.\n","        ì¦‰, pseudo labelë¥¼ ì´ìš©í•œ training íšŸìˆ˜ë¥¼ ê°€ë¦¬í‚¨ë‹¤.\n","        \"\"\"\n","        if N < 1:\n","            raise ValueError(f\"N must be bigger than 1, currently {N}\")\n","            \n","        # BONUS: ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ê¸°ëŠ¥ ì¶”ê°€\n","        # ë³„ë„ë¡œ ê´€ë ¨ ì •ë‹µ ì½”ë“œëŠ” ì œê³µë˜ì§€ \n","        \n","        # pseudo label trainingì„ ìœ„í•œ ì¤€ë¹„ ë‹¨ê³„\n","        print(\"Preparing for pseudo label process\")\n","        model = self.train(args, train_data, valid_data)\n","        self.validate(args, model, valid_data)\n","        pseudo_labels = self.test(args, model, test_data)\n","        pseudo_train_data = self.update_train_data(pseudo_labels, train_data, test_data)\n","\n","        # pseudo label training ì›í•˜ëŠ” íšŸìˆ˜ë§Œí¼ ë°˜ë³µ\n","        for i in range(N):\n","            print(f'Pseudo Label Training Process {i + 1}')\n","            model = self.train(args, pseudo_train_data, valid_data)\n","            self.validate(args, model, valid_data)\n","            pseudo_labels = self.test(args, model, test_data)\n","            pseudo_train_data = self.update_train_data(pseudo_labels, train_data, test_data)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-hRywCiuWXIC"},"source":["### PseudoLabel ì‚¬ìš©í•˜ê¸°\n","- ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n","- pseudo labeling ì§„í–‰í•˜ê¸°"]},{"cell_type":"markdown","metadata":{"id":"rEP6ZeopWXIC"},"source":["#### ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°"]},{"cell_type":"code","metadata":{"id":"yWS-R1ddWXIC","outputId":"59fb3570-1d8b-42ea-c75f-3d5a6ca58e55"},"source":["preprocess = Preprocess(args)\n","preprocess.load_train_data(file_name)\n","preprocess.load_test_data(test_file_name)\n","\n","data = preprocess.get_train_data()\n","train_data, valid_data = preprocess.split_data(data)\n","test_data = preprocess.get_test_data()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:61: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"G-WGqPGLWXIC"},"source":["#### pseudo labeling ì§„í–‰í•˜ê¸°"]},{"cell_type":"code","metadata":{"tags":[],"id":"0iKPvjVqWXID","outputId":"7fa3fd67-4bb4-46e2-b91a-3e4ed20c886a"},"source":["pseudo = PseudoLabel(Trainer())\n","\n","# pseudo label í›ˆë ¨!\n","N = 5\n","pseudo.run(N, args, train_data, valid_data, test_data)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["  0%|          | 0/20 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Preparing for pseudo label process\n","Training steps: 0 Loss: 0.6900253295898438\n","Training steps: 50 Loss: 0.6919722557067871\n","TRAIN AUC : 0.554705275834688 ACC : 0.4805887372013652\n"],"name":"stdout"},{"output_type":"stream","text":["  5%|â–Œ         | 1/20 [00:01<00:26,  1.40s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.6998257395654498 ACC : 0.4975124378109453\n","\n","Training steps: 0 Loss: 0.6921457052230835\n","Training steps: 50 Loss: 0.6847702264785767\n","TRAIN AUC : 0.7132778804401831 ACC : 0.5987627986348123\n"],"name":"stdout"},{"output_type":"stream","text":[" 10%|â–ˆ         | 2/20 [00:02<00:24,  1.38s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7281849640122946 ACC : 0.6696517412935323\n","\n","Training steps: 0 Loss: 0.6896021366119385\n","Training steps: 50 Loss: 0.6625217199325562\n","TRAIN AUC : 0.7311731988217779 ACC : 0.6785409556313993\n"],"name":"stdout"},{"output_type":"stream","text":[" 15%|â–ˆâ–Œ        | 3/20 [00:04<00:23,  1.38s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7332496248491214 ACC : 0.6796019900497512\n","\n","Training steps: 0 Loss: 0.6701774001121521\n","Training steps: 50 Loss: 0.6400703191757202\n","TRAIN AUC : 0.7367034762290696 ACC : 0.6883532423208191\n"],"name":"stdout"},{"output_type":"stream","text":[" 20%|â–ˆâ–ˆ        | 4/20 [00:05<00:22,  1.38s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7341640706126688 ACC : 0.6791044776119403\n","\n","Training steps: 0 Loss: 0.6247128248214722\n","Training steps: 50 Loss: 0.556143045425415\n","TRAIN AUC : 0.738649128868719 ACC : 0.6857935153583617\n"],"name":"stdout"},{"output_type":"stream","text":[" 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:06<00:20,  1.39s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7340420783904167 ACC : 0.6805970149253732\n","\n","Training steps: 0 Loss: 0.6126104593276978\n","Training steps: 50 Loss: 0.6219042539596558\n","TRAIN AUC : 0.7407162138631624 ACC : 0.683660409556314\n"],"name":"stdout"},{"output_type":"stream","text":[" 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:08<00:19,  1.39s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7345414530563019 ACC : 0.6796019900497512\n","\n","Training steps: 0 Loss: 0.6117020845413208\n","Training steps: 50 Loss: 0.6481729745864868\n","TRAIN AUC : 0.7431355620850263 ACC : 0.6868600682593856\n"],"name":"stdout"},{"output_type":"stream","text":[" 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:09<00:18,  1.41s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7348920567194406 ACC : 0.6810945273631841\n","\n","Training steps: 0 Loss: 0.6368664503097534\n","Training steps: 50 Loss: 0.6483151316642761\n","TRAIN AUC : 0.7440477633928855 ACC : 0.6870733788395904\n"],"name":"stdout"},{"output_type":"stream","text":[" 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:11<00:16,  1.39s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7351856314981934 ACC : 0.6805970149253732\n","\n","Training steps: 0 Loss: 0.6428849697113037\n","Training steps: 50 Loss: 0.5975516438484192\n","TRAIN AUC : 0.7450055474165084 ACC : 0.6870733788395904\n"],"name":"stdout"},{"output_type":"stream","text":[" 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:12<00:15,  1.38s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.735442509429602 ACC : 0.6810945273631841\n","\n","Training steps: 0 Loss: 0.6749882698059082\n","Training steps: 50 Loss: 0.576821506023407\n","TRAIN AUC : 0.7451300793959743 ACC : 0.683660409556314\n"],"name":"stdout"},{"output_type":"stream","text":[" 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:13<00:13,  1.35s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7356011984991981 ACC : 0.6810945273631841\n","\n","Training steps: 0 Loss: 0.6346455812454224\n","Training steps: 50 Loss: 0.5463368892669678\n","TRAIN AUC : 0.745564209180906 ACC : 0.6902730375426621\n"],"name":"stdout"},{"output_type":"stream","text":[" 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:15<00:12,  1.35s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7355406982914146 ACC : 0.6786069651741293\n","\n","Training steps: 0 Loss: 0.6111764311790466\n","Training steps: 50 Loss: 0.5960348844528198\n","TRAIN AUC : 0.746347502568586 ACC : 0.6892064846416383\n"],"name":"stdout"},{"output_type":"stream","text":[" 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:16<00:10,  1.36s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7359235356718152 ACC : 0.6786069651741293\n","\n","Training steps: 0 Loss: 0.6460267901420593\n","Training steps: 50 Loss: 0.5662584900856018\n","TRAIN AUC : 0.7465303804242293 ACC : 0.6896331058020477\n"],"name":"stdout"},{"output_type":"stream","text":[" 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:17<00:09,  1.36s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.736092142808261 ACC : 0.6791044776119403\n","\n","Training steps: 0 Loss: 0.5619603395462036\n","Training steps: 50 Loss: 0.5614066123962402\n","TRAIN AUC : 0.7467044152330142 ACC : 0.6892064846416383\n"],"name":"stdout"},{"output_type":"stream","text":[" 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:19<00:08,  1.36s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7361814054099087 ACC : 0.6810945273631841\n","\n","Training steps: 0 Loss: 0.5135862231254578\n","Training steps: 50 Loss: 0.5542420148849487\n","TRAIN AUC : 0.7475899962348678 ACC : 0.6909129692832765\n"],"name":"stdout"},{"output_type":"stream","text":[" 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:20<00:06,  1.33s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7361576020494693 ACC : 0.6810945273631841\n","\n","Training steps: 0 Loss: 0.5952599048614502\n","Training steps: 50 Loss: 0.658760666847229\n","TRAIN AUC : 0.7475126879489328 ACC : 0.6902730375426621\n"],"name":"stdout"},{"output_type":"stream","text":[" 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:21<00:05,  1.32s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7361853726366485 ACC : 0.6791044776119403\n","\n","Training steps: 0 Loss: 0.5879052877426147\n","Training steps: 50 Loss: 0.5566861033439636\n","TRAIN AUC : 0.7482433788826218 ACC : 0.6900597269624573\n"],"name":"stdout"},{"output_type":"stream","text":[" 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:23<00:03,  1.30s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7364129922708506 ACC : 0.6805970149253732\n","\n","Training steps: 0 Loss: 0.5696424245834351\n","Training steps: 50 Loss: 0.6097177267074585\n","TRAIN AUC : 0.7482762896034031 ACC : 0.691339590443686\n"],"name":"stdout"},{"output_type":"stream","text":[" 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:24<00:02,  1.32s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7362790983683788 ACC : 0.6825870646766169\n","\n","Training steps: 0 Loss: 0.5498515963554382\n","Training steps: 50 Loss: 0.6300085186958313\n","TRAIN AUC : 0.7484597144516354 ACC : 0.6900597269624573\n"],"name":"stdout"},{"output_type":"stream","text":[" 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:25<00:01,  1.34s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7362171104505679 ACC : 0.6830845771144278\n","\n","Training steps: 0 Loss: 0.6051499843597412\n","Training steps: 50 Loss: 0.6184108257293701\n","TRAIN AUC : 0.7485537060115397 ACC : 0.6902730375426621\n"],"name":"stdout"},{"output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:27<00:00,  1.36s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.736374807713479 ACC : 0.682089552238806\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7364129922708506 ACC : 0.6805970149253732\n","\n","AUC : 0.7364129922708506, ACC : 0.6805970149253732\n","Valid AUC : 0.7364129922708506 Valid ACC : 0.6805970149253732\n"],"name":"stdout"},{"output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","  0%|          | 0/20 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Pseudo Label Training Process 1\n","Training steps: 0 Loss: 0.695299506187439\n","Training steps: 50 Loss: 0.6892718076705933\n","TRAIN AUC : 0.7105193100831867 ACC : 0.49374079528718706\n"],"name":"stdout"},{"output_type":"stream","text":["  5%|â–Œ         | 1/20 [00:01<00:28,  1.48s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7255864304976588 ACC : 0.554228855721393\n","\n","Training steps: 0 Loss: 0.6886693239212036\n","Training steps: 50 Loss: 0.6782399415969849\n","TRAIN AUC : 0.7656024506060571 ACC : 0.6470913107511046\n"],"name":"stdout"},{"output_type":"stream","text":[" 10%|â–ˆ         | 2/20 [00:02<00:26,  1.45s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7336780853370307 ACC : 0.6681592039800995\n","\n","Training steps: 0 Loss: 0.6501531600952148\n","Training steps: 50 Loss: 0.629680335521698\n","TRAIN AUC : 0.7680605465559248 ACC : 0.7080265095729014\n"],"name":"stdout"},{"output_type":"stream","text":[" 15%|â–ˆâ–Œ        | 3/20 [00:04<00:24,  1.46s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.733590806348753 ACC : 0.6781094527363184\n","\n","Training steps: 0 Loss: 0.5785796642303467\n","Training steps: 50 Loss: 0.599791407585144\n","TRAIN AUC : 0.77292151406553 ACC : 0.7212812960235641\n"],"name":"stdout"},{"output_type":"stream","text":[" 20%|â–ˆâ–ˆ        | 4/20 [00:05<00:23,  1.45s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.732297490431545 ACC : 0.6805970149253732\n","\n","Training steps: 0 Loss: 0.48579418659210205\n","Training steps: 50 Loss: 0.6771537661552429\n","TRAIN AUC : 0.778598635645485 ACC : 0.7181516936671576\n"],"name":"stdout"},{"output_type":"stream","text":[" 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:07<00:21,  1.43s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7322776542978456 ACC : 0.6810945273631841\n","\n","Training steps: 0 Loss: 0.5394836664199829\n","Training steps: 50 Loss: 0.611693263053894\n","TRAIN AUC : 0.7801603868258215 ACC : 0.7192562592047128\n"],"name":"stdout"},{"output_type":"stream","text":[" 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:08<00:19,  1.43s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7324204744604819 ACC : 0.6800995024875622\n","\n","Training steps: 0 Loss: 0.6026964783668518\n","Training steps: 50 Loss: 0.6192831993103027\n","TRAIN AUC : 0.7824203805408245 ACC : 0.7205449189985272\n"],"name":"stdout"},{"output_type":"stream","text":[" 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:10<00:23,  1.67s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7328261233946368 ACC : 0.6776119402985075\n","\n","EarlyStopping counter: 5 out of 5\n"],"name":"stdout"},{"output_type":"stream","text":["\n","/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7336780853370307 ACC : 0.6681592039800995\n","\n","AUC : 0.7336780853370307, ACC : 0.6681592039800995\n","Valid AUC : 0.7336780853370307 Valid ACC : 0.6681592039800995\n","Pseudo Label Training Process 2\n"],"name":"stdout"},{"output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","  0%|          | 0/20 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Training steps: 0 Loss: 0.6932156085968018\n","Training steps: 50 Loss: 0.6911174058914185\n","TRAIN AUC : 0.704132195546251 ACC : 0.5977540500736377\n"],"name":"stdout"},{"output_type":"stream","text":["  5%|â–Œ         | 1/20 [00:01<00:27,  1.47s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7133619172019943 ACC : 0.6467661691542289\n","\n","Training steps: 0 Loss: 0.6798412799835205\n","Training steps: 50 Loss: 0.6805686354637146\n","TRAIN AUC : 0.7625013643818046 ACC : 0.6938512518409425\n"],"name":"stdout"},{"output_type":"stream","text":[" 10%|â–ˆ         | 2/20 [00:02<00:25,  1.43s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7290746146087175 ACC : 0.6711442786069651\n","\n","Training steps: 0 Loss: 0.6455870866775513\n","Training steps: 50 Loss: 0.6199886798858643\n","TRAIN AUC : 0.7695314729832063 ACC : 0.7128129602356407\n"],"name":"stdout"},{"output_type":"stream","text":[" 15%|â–ˆâ–Œ        | 3/20 [00:04<00:24,  1.43s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7326049505038874 ACC : 0.6671641791044776\n","\n","Training steps: 0 Loss: 0.6527020931243896\n","Training steps: 50 Loss: 0.6233759522438049\n","TRAIN AUC : 0.7806259139663208 ACC : 0.7170471281296024\n"],"name":"stdout"},{"output_type":"stream","text":[" 20%|â–ˆâ–ˆ        | 4/20 [00:05<00:23,  1.46s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.733384510558278 ACC : 0.672636815920398\n","\n","Training steps: 0 Loss: 0.5624276399612427\n","Training steps: 50 Loss: 0.5757415890693665\n","TRAIN AUC : 0.7831752232332019 ACC : 0.7190721649484536\n"],"name":"stdout"},{"output_type":"stream","text":[" 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:07<00:22,  1.47s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7345102111457252 ACC : 0.6771144278606965\n","\n","Training steps: 0 Loss: 0.6064525842666626\n","Training steps: 50 Loss: 0.5697993636131287\n","TRAIN AUC : 0.786078492122517 ACC : 0.7209131075110456\n"],"name":"stdout"},{"output_type":"stream","text":[" 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:08<00:20,  1.50s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.735363164894804 ACC : 0.6791044776119403\n","\n","Training steps: 0 Loss: 0.5389271378517151\n","Training steps: 50 Loss: 0.5702664256095886\n","TRAIN AUC : 0.7879482884042123 ACC : 0.7212812960235641\n"],"name":"stdout"},{"output_type":"stream","text":[" 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:10<00:18,  1.46s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7362409138110073 ACC : 0.6796019900497512\n","\n","Training steps: 0 Loss: 0.527924656867981\n","Training steps: 50 Loss: 0.5798054337501526\n","TRAIN AUC : 0.7902125181437356 ACC : 0.7209131075110456\n"],"name":"stdout"},{"output_type":"stream","text":[" 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:11<00:17,  1.44s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7369986541183285 ACC : 0.6810945273631841\n","\n","Training steps: 0 Loss: 0.5660969018936157\n","Training steps: 50 Loss: 0.5274959802627563\n","TRAIN AUC : 0.7909596231119838 ACC : 0.7220176730486009\n"],"name":"stdout"},{"output_type":"stream","text":[" 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:12<00:15,  1.41s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7381184038656659 ACC : 0.6825870646766169\n","\n","Training steps: 0 Loss: 0.5843253135681152\n","Training steps: 50 Loss: 0.5911906361579895\n","TRAIN AUC : 0.7928643340088012 ACC : 0.7218335787923417\n"],"name":"stdout"},{"output_type":"stream","text":[" 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:14<00:13,  1.40s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7386589385089773 ACC : 0.6830845771144278\n","\n","Training steps: 0 Loss: 0.5262203216552734\n","Training steps: 50 Loss: 0.4923822283744812\n","TRAIN AUC : 0.7937632328086197 ACC : 0.7245949926362297\n"],"name":"stdout"},{"output_type":"stream","text":[" 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:15<00:12,  1.38s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7390199561423084 ACC : 0.6855721393034826\n","\n","Training steps: 0 Loss: 0.5952982902526855\n","Training steps: 50 Loss: 0.5126656889915466\n","TRAIN AUC : 0.7949468043635812 ACC : 0.7234904270986745\n"],"name":"stdout"},{"output_type":"stream","text":[" 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:16<00:10,  1.37s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7392173256726186 ACC : 0.6840796019900498\n","\n","Training steps: 0 Loss: 0.595156192779541\n","Training steps: 50 Loss: 0.513518214225769\n","TRAIN AUC : 0.7955286242217938 ACC : 0.7234904270986745\n"],"name":"stdout"},{"output_type":"stream","text":[" 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:18<00:09,  1.39s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7399096067387314 ACC : 0.682089552238806\n","\n","Training steps: 0 Loss: 0.5531013607978821\n","Training steps: 50 Loss: 0.5411888360977173\n","TRAIN AUC : 0.7971582893058906 ACC : 0.7247790868924889\n"],"name":"stdout"},{"output_type":"stream","text":[" 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:19<00:08,  1.43s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7400038283738041 ACC : 0.682089552238806\n","\n","Training steps: 0 Loss: 0.5508502125740051\n","Training steps: 50 Loss: 0.507623553276062\n","TRAIN AUC : 0.7972812701055642 ACC : 0.7253313696612665\n"],"name":"stdout"},{"output_type":"stream","text":[" 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:21<00:07,  1.45s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7403311245798458 ACC : 0.6830845771144278\n","\n","Training steps: 0 Loss: 0.5407091379165649\n","Training steps: 50 Loss: 0.6097264289855957\n","TRAIN AUC : 0.7983209798871478 ACC : 0.7249631811487481\n"],"name":"stdout"},{"output_type":"stream","text":[" 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:22<00:05,  1.47s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.740815126242114 ACC : 0.682089552238806\n","\n","Training steps: 0 Loss: 0.5629013776779175\n","Training steps: 50 Loss: 0.45089012384414673\n","TRAIN AUC : 0.7988492414037167 ACC : 0.7268041237113402\n"],"name":"stdout"},{"output_type":"stream","text":[" 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:24<00:04,  1.46s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7410229097426163 ACC : 0.6776119402985075\n","\n","Training steps: 0 Loss: 0.4723399877548218\n","Training steps: 50 Loss: 0.5731489062309265\n","TRAIN AUC : 0.7987636836478247 ACC : 0.7238586156111929\n"],"name":"stdout"},{"output_type":"stream","text":[" 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:25<00:02,  1.49s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7410372909395484 ACC : 0.6771144278606965\n","\n","Training steps: 0 Loss: 0.7087174654006958\n","Training steps: 50 Loss: 0.5274882316589355\n","TRAIN AUC : 0.7998071221747127 ACC : 0.7262518409425626\n"],"name":"stdout"},{"output_type":"stream","text":[" 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:27<00:01,  1.51s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7414588087806631 ACC : 0.6800995024875622\n","\n","Training steps: 0 Loss: 0.5029172301292419\n","Training steps: 50 Loss: 0.5803655385971069\n","TRAIN AUC : 0.8006250055083738 ACC : 0.7279086892488954\n"],"name":"stdout"},{"output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:28<00:00,  1.45s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7409986104788344 ACC : 0.6800995024875622\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7414588087806631 ACC : 0.6800995024875622\n","\n","AUC : 0.7414588087806631, ACC : 0.6800995024875622\n","Valid AUC : 0.7414588087806631 Valid ACC : 0.6800995024875622\n"],"name":"stdout"},{"output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","  0%|          | 0/20 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Pseudo Label Training Process 3\n","Training steps: 0 Loss: 0.6935940384864807\n","Training steps: 50 Loss: 0.6910767555236816\n","TRAIN AUC : 0.6852935028979258 ACC : 0.5907584683357879\n"],"name":"stdout"},{"output_type":"stream","text":["  5%|â–Œ         | 1/20 [00:01<00:29,  1.56s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.6949648950023852 ACC : 0.6009950248756218\n","\n","Training steps: 0 Loss: 0.683268129825592\n","Training steps: 50 Loss: 0.6760495901107788\n","TRAIN AUC : 0.7529112520306369 ACC : 0.6386229749631811\n"],"name":"stdout"},{"output_type":"stream","text":[" 10%|â–ˆ         | 2/20 [00:03<00:28,  1.56s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7144935686295513 ACC : 0.645273631840796\n","\n","Training steps: 0 Loss: 0.6787689328193665\n","Training steps: 50 Loss: 0.6539921164512634\n","TRAIN AUC : 0.7661075263333437 ACC : 0.6726804123711341\n"],"name":"stdout"},{"output_type":"stream","text":[" 15%|â–ˆâ–Œ        | 3/20 [00:04<00:25,  1.53s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.723018147086915 ACC : 0.6616915422885572\n","\n","Training steps: 0 Loss: 0.6474252343177795\n","Training steps: 50 Loss: 0.5815122127532959\n","TRAIN AUC : 0.7801326029438114 ACC : 0.7083946980854198\n"],"name":"stdout"},{"output_type":"stream","text":[" 20%|â–ˆâ–ˆ        | 4/20 [00:05<00:23,  1.49s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7237991948513331 ACC : 0.6736318407960199\n","\n","Training steps: 0 Loss: 0.6079463362693787\n","Training steps: 50 Loss: 0.5541277527809143\n","TRAIN AUC : 0.7870717962121544 ACC : 0.7139175257731959\n"],"name":"stdout"},{"output_type":"stream","text":[" 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:07<00:22,  1.51s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7255958526611661 ACC : 0.6716417910447762\n","\n","Training steps: 0 Loss: 0.6159007549285889\n","Training steps: 50 Loss: 0.5067154169082642\n","TRAIN AUC : 0.7931844251627663 ACC : 0.7187039764359352\n"],"name":"stdout"},{"output_type":"stream","text":[" 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:08<00:20,  1.50s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7271004234022738 ACC : 0.6751243781094527\n","\n","Training steps: 0 Loss: 0.45100608468055725\n","Training steps: 50 Loss: 0.5592769384384155\n","TRAIN AUC : 0.7954934205127656 ACC : 0.7238586156111929\n"],"name":"stdout"},{"output_type":"stream","text":[" 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:10<00:18,  1.45s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7292814063025348 ACC : 0.6751243781094527\n","\n","Training steps: 0 Loss: 0.6017005443572998\n","Training steps: 50 Loss: 0.5215414762496948\n","TRAIN AUC : 0.7977276127414605 ACC : 0.7260677466863034\n"],"name":"stdout"},{"output_type":"stream","text":[" 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:11<00:17,  1.43s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7305479434392484 ACC : 0.672636815920398\n","\n","Training steps: 0 Loss: 0.5751490592956543\n","Training steps: 50 Loss: 0.5031553506851196\n","TRAIN AUC : 0.7992876952459802 ACC : 0.7268041237113402\n"],"name":"stdout"},{"output_type":"stream","text":[" 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:13<00:15,  1.45s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7317638984350282 ACC : 0.6791044776119403\n","\n","Training steps: 0 Loss: 0.48266834020614624\n","Training steps: 50 Loss: 0.5523114800453186\n","TRAIN AUC : 0.8007282148285965 ACC : 0.7290132547864506\n"],"name":"stdout"},{"output_type":"stream","text":[" 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:14<00:14,  1.45s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.732482462378293 ACC : 0.6756218905472637\n","\n","Training steps: 0 Loss: 0.5717706084251404\n","Training steps: 50 Loss: 0.5199447274208069\n","TRAIN AUC : 0.8015693599904621 ACC : 0.7317746686303387\n"],"name":"stdout"},{"output_type":"stream","text":[" 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:16<00:12,  1.43s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7330433290586464 ACC : 0.6766169154228856\n","\n","Training steps: 0 Loss: 0.47590330243110657\n","Training steps: 50 Loss: 0.5977900624275208\n","TRAIN AUC : 0.8023804618316226 ACC : 0.7299337260677466\n"],"name":"stdout"},{"output_type":"stream","text":[" 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:17<00:11,  1.45s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7335362569810793 ACC : 0.6786069651741293\n","\n","Training steps: 0 Loss: 0.5139116048812866\n","Training steps: 50 Loss: 0.5402935743331909\n","TRAIN AUC : 0.8031263228725158 ACC : 0.7323269513991163\n"],"name":"stdout"},{"output_type":"stream","text":[" 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:19<00:10,  1.46s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7342865587382632 ACC : 0.6781094527363184\n","\n","Training steps: 0 Loss: 0.5302945375442505\n","Training steps: 50 Loss: 0.5848063230514526\n","TRAIN AUC : 0.8038007038682098 ACC : 0.7319587628865979\n"],"name":"stdout"},{"output_type":"stream","text":[" 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:20<00:08,  1.44s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7346331951746621 ACC : 0.6800995024875622\n","\n","Training steps: 0 Loss: 0.5110727548599243\n","Training steps: 50 Loss: 0.5421818494796753\n","TRAIN AUC : 0.8039999527987558 ACC : 0.7323269513991163\n"],"name":"stdout"},{"output_type":"stream","text":[" 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:21<00:07,  1.43s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7350368604954471 ACC : 0.6800995024875622\n","\n","Training steps: 0 Loss: 0.599565863609314\n","Training steps: 50 Loss: 0.6217672228813171\n","TRAIN AUC : 0.8045298817106978 ACC : 0.7314064801178203\n"],"name":"stdout"},{"output_type":"stream","text":[" 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:23<00:05,  1.44s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7354266405226425 ACC : 0.6776119402985075\n","\n","Training steps: 0 Loss: 0.6204420924186707\n","Training steps: 50 Loss: 0.5196070671081543\n","TRAIN AUC : 0.8047660235677982 ACC : 0.7319587628865979\n"],"name":"stdout"},{"output_type":"stream","text":[" 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:24<00:04,  1.46s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.735642854379967 ACC : 0.6791044776119403\n","\n","Training steps: 0 Loss: 0.5547069907188416\n","Training steps: 50 Loss: 0.5088458061218262\n","TRAIN AUC : 0.8054969646751585 ACC : 0.7334315169366715\n"],"name":"stdout"},{"output_type":"stream","text":[" 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:26<00:03,  1.57s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7363152993123804 ACC : 0.6786069651741293\n","\n","Training steps: 0 Loss: 0.49665841460227966\n","Training steps: 50 Loss: 0.4516596794128418\n","TRAIN AUC : 0.805154755654214 ACC : 0.7325110456553755\n"],"name":"stdout"},{"output_type":"stream","text":[" 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:28<00:01,  1.59s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.736416463594248 ACC : 0.6781094527363184\n","\n","Training steps: 0 Loss: 0.6042577028274536\n","Training steps: 50 Loss: 0.5431730151176453\n","TRAIN AUC : 0.806281753178997 ACC : 0.7323269513991163\n"],"name":"stdout"},{"output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:30<00:00,  1.50s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7362399220043223 ACC : 0.6776119402985075\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.736416463594248 ACC : 0.6781094527363184\n","\n","AUC : 0.736416463594248, ACC : 0.6781094527363184\n","Valid AUC : 0.736416463594248 Valid ACC : 0.6781094527363184\n"],"name":"stdout"},{"output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","  0%|          | 0/20 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Pseudo Label Training Process 4\n","Training steps: 0 Loss: 0.6941017508506775\n","Training steps: 50 Loss: 0.6878567934036255\n","TRAIN AUC : 0.6915537723733547 ACC : 0.5885493372606775\n"],"name":"stdout"},{"output_type":"stream","text":["  5%|â–Œ         | 1/20 [00:01<00:31,  1.68s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7198865174791051 ACC : 0.6676616915422886\n","\n","Training steps: 0 Loss: 0.681498646736145\n","Training steps: 50 Loss: 0.6698458790779114\n","TRAIN AUC : 0.7637246874022654 ACC : 0.7102356406480118\n"],"name":"stdout"},{"output_type":"stream","text":[" 10%|â–ˆ         | 2/20 [00:03<00:28,  1.59s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7277743560447145 ACC : 0.6761194029850747\n","\n","Training steps: 0 Loss: 0.6617467403411865\n","Training steps: 50 Loss: 0.6442924737930298\n","TRAIN AUC : 0.7736845318818821 ACC : 0.716678939617084\n"],"name":"stdout"},{"output_type":"stream","text":[" 15%|â–ˆâ–Œ        | 3/20 [00:04<00:26,  1.54s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7294232346584862 ACC : 0.6721393034825871\n","\n","Training steps: 0 Loss: 0.6297067403793335\n","Training steps: 50 Loss: 0.5975683927536011\n","TRAIN AUC : 0.7822856421796462 ACC : 0.7218335787923417\n"],"name":"stdout"},{"output_type":"stream","text":[" 20%|â–ˆâ–ˆ        | 4/20 [00:05<00:24,  1.52s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7280525578198502 ACC : 0.6746268656716418\n","\n","Training steps: 0 Loss: 0.6115447282791138\n","Training steps: 50 Loss: 0.5766034126281738\n","TRAIN AUC : 0.7872144117545297 ACC : 0.7223858615611193\n"],"name":"stdout"},{"output_type":"stream","text":[" 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:07<00:22,  1.51s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7281100826075788 ACC : 0.6786069651741293\n","\n","Training steps: 0 Loss: 0.5938544273376465\n","Training steps: 50 Loss: 0.51514732837677\n","TRAIN AUC : 0.7909000494566216 ACC : 0.7242268041237113\n"],"name":"stdout"},{"output_type":"stream","text":[" 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:08<00:20,  1.50s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7281150416410036 ACC : 0.6810945273631841\n","\n","Training steps: 0 Loss: 0.4810349643230438\n","Training steps: 50 Loss: 0.47569048404693604\n","TRAIN AUC : 0.792925532167496 ACC : 0.7273564064801178\n"],"name":"stdout"},{"output_type":"stream","text":[" 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:10<00:19,  1.49s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7284869691478694 ACC : 0.6825870646766169\n","\n","Training steps: 0 Loss: 0.5489698052406311\n","Training steps: 50 Loss: 0.4997878074645996\n","TRAIN AUC : 0.7949544748066342 ACC : 0.7277245949926362\n"],"name":"stdout"},{"output_type":"stream","text":[" 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:11<00:22,  1.70s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7287289699790036 ACC : 0.6805970149253732\n","\n","EarlyStopping counter: 5 out of 5\n"],"name":"stdout"},{"output_type":"stream","text":["\n","/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7294232346584862 ACC : 0.6721393034825871\n","\n","AUC : 0.7294232346584862, ACC : 0.6721393034825871\n","Valid AUC : 0.7294232346584862 Valid ACC : 0.6721393034825871\n"],"name":"stdout"},{"output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","  0%|          | 0/20 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Pseudo Label Training Process 5\n","Training steps: 0 Loss: 0.6963937282562256\n","Training steps: 50 Loss: 0.682644784450531\n","TRAIN AUC : 0.6897737746448938 ACC : 0.5281664212076583\n"],"name":"stdout"},{"output_type":"stream","text":["  5%|â–Œ         | 1/20 [00:01<00:28,  1.51s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7074100852854568 ACC : 0.56318407960199\n","\n","Training steps: 0 Loss: 0.678922176361084\n","Training steps: 50 Loss: 0.662775993347168\n","TRAIN AUC : 0.7624478369795251 ACC : 0.6458026509572902\n"],"name":"stdout"},{"output_type":"stream","text":[" 10%|â–ˆ         | 2/20 [00:03<00:28,  1.57s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7277560076210426 ACC : 0.6527363184079602\n","\n","Training steps: 0 Loss: 0.6784322261810303\n","Training steps: 50 Loss: 0.6128625273704529\n","TRAIN AUC : 0.7759345234063975 ACC : 0.7137334315169367\n"],"name":"stdout"},{"output_type":"stream","text":[" 15%|â–ˆâ–Œ        | 3/20 [00:05<00:27,  1.64s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7317232343609442 ACC : 0.6741293532338308\n","\n","Training steps: 0 Loss: 0.627672553062439\n","Training steps: 50 Loss: 0.5899879932403564\n","TRAIN AUC : 0.777719266553357 ACC : 0.7229381443298969\n"],"name":"stdout"},{"output_type":"stream","text":[" 20%|â–ˆâ–ˆ        | 4/20 [00:06<00:26,  1.68s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7319523417051736 ACC : 0.6776119402985075\n","\n","Training steps: 0 Loss: 0.5661249756813049\n","Training steps: 50 Loss: 0.6449853181838989\n","TRAIN AUC : 0.7844442873086304 ACC : 0.7242268041237113\n"],"name":"stdout"},{"output_type":"stream","text":[" 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:08<00:24,  1.61s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7327785166737582 ACC : 0.682089552238806\n","\n","Training steps: 0 Loss: 0.5942034721374512\n","Training steps: 50 Loss: 0.5119948387145996\n","TRAIN AUC : 0.7877674383316954 ACC : 0.7268041237113402\n"],"name":"stdout"},{"output_type":"stream","text":[" 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:09<00:22,  1.59s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7333607071978386 ACC : 0.6796019900497512\n","\n","Training steps: 0 Loss: 0.6499292254447937\n","Training steps: 50 Loss: 0.5322772860527039\n","TRAIN AUC : 0.789203783329739 ACC : 0.7253313696612665\n"],"name":"stdout"},{"output_type":"stream","text":[" 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:11<00:20,  1.57s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7340450538104718 ACC : 0.6800995024875622\n","\n","Training steps: 0 Loss: 0.5630466341972351\n","Training steps: 50 Loss: 0.616181492805481\n","TRAIN AUC : 0.7911577038404008 ACC : 0.7271723122238586\n"],"name":"stdout"},{"output_type":"stream","text":[" 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:12<00:18,  1.54s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7347036134492954 ACC : 0.6845771144278607\n","\n","Training steps: 0 Loss: 0.5326693058013916\n","Training steps: 50 Loss: 0.5690150260925293\n","TRAIN AUC : 0.7920899776561015 ACC : 0.7286450662739322\n"],"name":"stdout"},{"output_type":"stream","text":[" 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:14<00:16,  1.49s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7351142214168753 ACC : 0.6825870646766169\n","\n","Training steps: 0 Loss: 0.5752013921737671\n","Training steps: 50 Loss: 0.5712608098983765\n","TRAIN AUC : 0.7931636058434798 ACC : 0.7291973490427098\n"],"name":"stdout"},{"output_type":"stream","text":[" 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:15<00:14,  1.48s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7352927466201706 ACC : 0.6786069651741293\n","\n","Training steps: 0 Loss: 0.5716575384140015\n","Training steps: 50 Loss: 0.61927729845047\n","TRAIN AUC : 0.7935646640943743 ACC : 0.7242268041237113\n"],"name":"stdout"},{"output_type":"stream","text":[" 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:17<00:13,  1.46s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7356011984991981 ACC : 0.6865671641791045\n","\n","Training steps: 0 Loss: 0.49204105138778687\n","Training steps: 50 Loss: 0.4838632345199585\n","TRAIN AUC : 0.7950684628828392 ACC : 0.728460972017673\n"],"name":"stdout"},{"output_type":"stream","text":[" 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:18<00:11,  1.47s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7356279772796925 ACC : 0.6761194029850747\n","\n","Training steps: 0 Loss: 0.48221173882484436\n","Training steps: 50 Loss: 0.6115179061889648\n","TRAIN AUC : 0.7949530992573703 ACC : 0.7271723122238586\n"],"name":"stdout"},{"output_type":"stream","text":[" 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:20<00:10,  1.49s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7360227163403127 ACC : 0.6751243781094527\n","\n","Training steps: 0 Loss: 0.603839635848999\n","Training steps: 50 Loss: 0.48714086413383484\n","TRAIN AUC : 0.7971239033839137 ACC : 0.7280927835051546\n"],"name":"stdout"},{"output_type":"stream","text":[" 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:21<00:09,  1.50s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7355109440908654 ACC : 0.6875621890547263\n","\n","Training steps: 0 Loss: 0.5081406831741333\n","Training steps: 50 Loss: 0.5618892312049866\n","TRAIN AUC : 0.796415638584491 ACC : 0.7290132547864506\n"],"name":"stdout"},{"output_type":"stream","text":[" 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:23<00:07,  1.49s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7359255192851851 ACC : 0.6855721393034826\n","\n","Training steps: 0 Loss: 0.4826825261116028\n","Training steps: 50 Loss: 0.5475196838378906\n","TRAIN AUC : 0.7969551331859484 ACC : 0.7269882179675994\n"],"name":"stdout"},{"output_type":"stream","text":[" 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:24<00:05,  1.49s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7359423799988296 ACC : 0.6805970149253732\n","\n","Training steps: 0 Loss: 0.5790255069732666\n","Training steps: 50 Loss: 0.6028715968132019\n","TRAIN AUC : 0.7975941798100897 ACC : 0.730301914580265\n"],"name":"stdout"},{"output_type":"stream","text":[" 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:26<00:04,  1.50s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7362627335580769 ACC : 0.6791044776119403\n","\n","Training steps: 0 Loss: 0.4728904366493225\n","Training steps: 50 Loss: 0.6083180904388428\n","TRAIN AUC : 0.7980710387490131 ACC : 0.7291973490427098\n"],"name":"stdout"},{"output_type":"stream","text":[" 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:27<00:03,  1.51s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7364234062410427 ACC : 0.6800995024875622\n","\n","Training steps: 0 Loss: 0.4994639456272125\n","Training steps: 50 Loss: 0.4803105592727661\n","TRAIN AUC : 0.7979809872601912 ACC : 0.7288291605301914\n"],"name":"stdout"},{"output_type":"stream","text":[" 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:29<00:01,  1.50s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7363787749402189 ACC : 0.6805970149253732\n","\n","Training steps: 0 Loss: 0.4414767026901245\n","Training steps: 50 Loss: 0.5936368703842163\n","TRAIN AUC : 0.7984164510158582 ACC : 0.7280927835051546\n"],"name":"stdout"},{"output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:30<00:00,  1.53s/it]"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7363262091859152 ACC : 0.682089552238806\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n"],"name":"stderr"},{"output_type":"stream","text":["VALID AUC : 0.7364234062410427 ACC : 0.6800995024875622\n","\n","AUC : 0.7364234062410427, ACC : 0.6800995024875622\n","Valid AUC : 0.7364234062410427 Valid ACC : 0.6800995024875622\n"],"name":"stdout"},{"output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"rGkNDwvkWXID"},"source":["#### ì‹œê°í™”"]},{"cell_type":"code","metadata":{"id":"8T2nGBL8WXID","outputId":"0ba860a3-85f0-4775-eef3-1e00d9e8b9e7"},"source":["!pip install matplotlib"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (3.4.2)\n","Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (2.8.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (1.3.1)\n","Requirement already satisfied: numpy>=1.16 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (1.18.5)\n","Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (7.2.0)\n","Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (2.4.7)\n","Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib) (1.14.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fIQMZxwDWXID","outputId":"026143c6-8e6c-495b-93bd-6f5400c65630"},"source":["# ê²°ê³¼ ì‹œê°í™”\n","\n","pseudo.visualize()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 792x504 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"HeOKb96RWXID"},"source":["### output.csv ìƒì„±\n","> í˜„ì¬ ì‹¤í—˜ì—ì„œëŠ” pseudo1 ëª¨ë¸ì´ ê°€ì¥ valid AUCê°€ ë†’ê¸° ë•Œë¬¸ì— pseudo1ì˜ test set ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì œì¶œ"]},{"cell_type":"code","metadata":{"id":"FAsyMjFMWXIE"},"source":["pseudo1_pred = pseudo.preds[1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xr0TOIyZWXIE","outputId":"83ae0782-e609-4633-bc6b-8148411fd4ff"},"source":["write_path = os.path.join(args.output_dir, \"output.csv\")\n","if not os.path.exists(args.output_dir):\n","    os.makedirs(args.output_dir)    \n","\n","with open(write_path, 'w', encoding='utf8') as w:\n","    print(\"writing prediction : {}\".format(write_path))\n","    w.write(\"id,prediction\\n\")\n","    for id, p in enumerate(pseudo1_pred):\n","        w.write('{},{}\\n'.format(id,p))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["writing prediction : output/output.csv\n"],"name":"stdout"}]}]}